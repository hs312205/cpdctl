{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52836fdc-3186-422c-a7f3-7361e43e0492",
    "tags": []
   },
   "source": [
    "# CPDCTL Samples for Notebooks and Environments in Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f784a75b-7a1a-477b-9c3e-b3031e55b7b0"
   },
   "source": [
    "CPDCTL is a command-line interface (CLI) you can use to manage the lifecycle of notebooks. By using the notebook CLI, you can automate the flow for creating notebooks and running notebook jobs, moving notebooks between projects in Watson Studio, and adding custom libraries to notebook runtime environments.   \n",
    "\n",
    "This notebook begins by showing you how to install and configure CPDCTL and is then split up into four sections with examples of how to use the commands for:\n",
    "\n",
    "- Creating notebooks and running notebook jobs\n",
    "- Creating Python scripts and running script jobs\n",
    "- Downloading notebooks from one project and uploading them to another project\n",
    "- Adding custom libraries to a notebook runtime environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82580eb7-e2b9-4e9e-9885-fa158062b875"
   },
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de809145-e7d2-4b12-9aa6-3243a2c2621e"
   },
   "source": [
    "[1. Installing and configuring CPDCTL](#part1)\n",
    "- [1.1 Installing the latest version of CPDCTL](#part1.1)\n",
    "- [1.2 Adding CPD cluster configuration settings](#part1.2)\n",
    "\n",
    "[2. Demo 1: Creating a notebook asset and running a job](#part2)\n",
    "- [2.1 Creating a notebook asset](#part2.1)\n",
    "- [2.2 Running a job](#part2.2)\n",
    "\n",
    "[3. Demo 2: Creating a Python script asset and running a job](#part3)\n",
    "- [3.1 Creating a Python script asset](#part3.1)\n",
    "- [3.2 Running a job](#part3.2)\n",
    "\n",
    "[4. Demo 3: Downloading a notebook and uploading it to another project](#part4)\n",
    "- [4.1 Downloading a notebook](#part4.1)\n",
    "- [4.2 Uploading the notebook to another project](#part4.2)\n",
    "\n",
    "[5. Demo 4: Adding additional packages to custom environment](#part5)\n",
    "- [5.1 Creating a custom software specification](#part5.1)\n",
    "- [5.2 Adding additional packages](#part5.2)\n",
    "- [5.3 Creating a custom environment](#part5.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bcac300-cc2c-462d-92f7-a0cdf87748d8"
   },
   "source": [
    "## Before you begin\n",
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c60b7d21-abe0-4838-aa5b-f393f80e8e20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import platform\n",
    "import tarfile\n",
    "import zipfile\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f69d289-71ad-4021-a88e-a32ec96695b4"
   },
   "source": [
    "##  1. Installing and configuring CPDCTL <a class=\"anchor\" id=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a14fb99-4cfa-4ee4-8492-c9f08e0c93db"
   },
   "source": [
    "### 1.1 Installing the latest version of CPDCTL <a class=\"anchor\" id=\"part1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "046f0111-b320-44ee-8da6-b66b92fad1ef"
   },
   "source": [
    "To use the notebook and environment CLI commands, you need to install CPDCTL. Download the binary from the [CPDCTL GitHub respository](https://github.com/IBM/cpdctl/releases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2f9b0654-9907-487f-b86a-a80a1796ab32"
   },
   "source": [
    "Download the binary and then display the version number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "847a7a9f-8741-4708-a611-95f577c88c51",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<code>cpdctl</code> binary downloaded from: <a href=\"https://github.com/IBM/cpdctl/releases/download/v1.1.132/cpdctl_linux_amd64.tar.gz\">cpdctl_linux_amd64.tar.gz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PLATFORM = platform.system().lower()\n",
    "CPDCTL_ARCH = \"{}_amd64\".format(PLATFORM)\n",
    "CPDCTL_RELEASES_URL=\"https://api.github.com/repos/IBM/cpdctl/releases\"\n",
    "CWD = os.getcwd()\n",
    "PATH = os.environ['PATH']\n",
    "CPD_CONFIG = os.path.join(CWD, '.cpdctl.config.yml')\n",
    "\n",
    "response = requests.get(CPDCTL_RELEASES_URL)\n",
    "assets = response.json()[0]['assets']\n",
    "platform_asset = next(a for a in assets if CPDCTL_ARCH in a['name'])\n",
    "cpdctl_url = platform_asset['url']\n",
    "cpdctl_file_name = platform_asset['name']\n",
    "\n",
    "response = requests.get(cpdctl_url, headers={'Accept': 'application/octet-stream'})\n",
    "with open(cpdctl_file_name, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "    \n",
    "display(HTML('<code>cpdctl</code> binary downloaded from: <a href=\"{}\">{}</a>'.format(platform_asset['browser_download_url'], platform_asset['name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "a5c9036a-4a39-4e97-acba-c4f3ddf5d091",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%env PATH={CWD}:{PATH}\n",
    "%env CPD_CONFIG={CPD_CONFIG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "83f29558-661a-4ebe-a8df-4f98d61b8e77",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpdctl version: 1.1.132\n"
     ]
    }
   ],
   "source": [
    "if cpdctl_file_name.endswith('tar.gz'):\n",
    "    with tarfile.open(cpdctl_file_name, \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "elif cpdctl_file_name.endswith('zip'):\n",
    "    with zipfile.ZipFile(cpdctl_file_name, 'r') as zf:\n",
    "        zf.extractall()\n",
    "\n",
    "if CPD_CONFIG and os.path.exists(CPD_CONFIG):\n",
    "    os.remove(CPD_CONFIG)\n",
    "    \n",
    "version_r = ! cpdctl version\n",
    "CPDCTL_VERSION = version_r.s\n",
    "\n",
    "print(\"cpdctl version: {}\".format(CPDCTL_VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfb45d0a-b69e-44b0-a3cc-e7e312df6be7"
   },
   "source": [
    "### 1.2  Adding CPD cluster configuration settings <a class=\"anchor\" id=\"part1.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31aeed20-a677-4881-9b8e-378bbeefa4a4"
   },
   "source": [
    "Before you can use CPDCTL, you need to add configuration settings. You only need to configure these settings once for the same IBM Cloud Pak for Data (CPD) user and cluster. Begin by entering your CPD credentials and the URL to the CPD cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07ec6f59-5f8e-4d64-ada2-266f536b1d24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CPD_USER_NAME = 'dhshi'\n",
    "CPD_USER_PASSWORD = 'passw0rd'\n",
    "CPD_URL = 'https://cpd-cpd-instance.apps.cp4d404ugi.cp.fyre.ibm.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cccd5eda-9814-48ff-b965-daf2d9e3c533"
   },
   "source": [
    "Add \"cpd_user\" user to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dd5ed7f6-c50d-4529-8fc6-25d0b9b65809",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cpdctl config user set cpd_user --username {CPD_USER_NAME} --password {CPD_USER_PASSWORD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dc9eb01-269f-4081-ad4a-7b4535bf74a2"
   },
   "source": [
    "Add \"cpd\" cluster to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a8462a1d-958f-4ca8-a0bc-5b6c45ef10dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cpdctl config profile set cpd --url {CPD_URL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84faba39-9030-4429-8565-3f7deea07a32"
   },
   "source": [
    "Add \"cpd\" context to the cpdctl configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "606cb03b-a43b-4a5c-a822-a627420c4ff5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cpdctl config context set cpd --profile cpd --user cpd_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "625876c5-5857-4081-9ba5-970ac3155791"
   },
   "source": [
    "List available contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0caa8637-67ec-46e8-848e-485fe9917821",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mName\u001b[0m                          \u001b[1mProfile\u001b[0m                       \u001b[1mUser\u001b[0m                       \u001b[1mCurrent\u001b[0m   \n",
      "\u001b[36;1minClusterEnvironmentContext\u001b[0m   inClusterEnvironmentProfile   inClusterEnvironmentUser   *   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl config context list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5976f227-6063-46e0-a970-50b7cffabc8a"
   },
   "source": [
    "Switch to the context you just created if it is not marked in the `Current` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e4459bfd-850c-42ae-aa1b-c5ba3f241562",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to context \"inClusterEnvironmentContext\".\n"
     ]
    }
   ],
   "source": [
    "! cpdctl config context use inClusterEnvironmentContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fd3a507-bfa7-4810-a702-3863860dda73",
    "tags": []
   },
   "source": [
    "List available projects in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "70255e65-22f2-4af7-b194-b4159687c437",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                                                \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m                                          \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1m0619c2d3-2b75-42f7-97c1-9d898fdef44c\u001b[0m   Mortgage default project                            2022-02-11T12:02:58.633Z                                                        []   \n",
      "\u001b[36;1m19a29ada-3e9c-4147-bf35-4cf431ed3a26\u001b[0m   AutoAI-TD-Sub                                       2022-01-25T01:20:57.078Z   The classification goal to train a model that can…   []   \n",
      "\u001b[36;1m25fc9237-bda9-42f9-ab83-124bb92b3ae9\u001b[0m   cpdctl-samples-project-notebook-project-test        2022-04-03T15:46:00.738Z                                                        []   \n",
      "\u001b[36;1m2ba058a6-4ef7-4b3b-acde-44baaf288efb\u001b[0m   test-analytics-project-git-ibm-sk-1                 2022-04-01T13:10:46.824Z                                                        []   \n",
      "\u001b[36;1m32d75b88-b113-4bd4-9502-cd2f471a8623\u001b[0m   MLOps-CPD3.0-SWAT-StarterKit-AutoAI-Project-v0.96   2022-01-24T16:02:06.209Z                                                        []   \n",
      "\u001b[36;1m3ea4045c-4ff0-4995-8c80-849d1854b69f\u001b[0m   julian                                              2022-03-30T14:18:22.669Z                                                        []   \n",
      "\u001b[36;1m4aab8ced-62cb-4b13-8708-9883b534c4a6\u001b[0m   test-analytics-project-git-existing-repo            2022-02-11T03:06:38.611Z                                                        []   \n",
      "\u001b[36;1m632cbaf4-f262-45c6-b16b-6746dcc77571\u001b[0m   test-analytics-project-git-ibm-sk-2                 2022-02-15T03:47:31.580Z                                                        []   \n",
      "\u001b[36;1m635a5511-72f6-4eb3-8ec6-0763a25e39cb\u001b[0m   cpdctl-samples-project                              2022-04-03T02:09:06.178Z   cpdctl utility and notebook tutorials sample proj…   []   \n",
      "\u001b[36;1m6d0fa8ad-0b6c-475d-a39e-d672b544d5b6\u001b[0m   MLOps-CPD3.0-SWAT-StarterKit-AutoAI-Project-v0.96   2022-03-29T16:36:07.200Z                                                        []   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl project list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c709069-5990-411a-8c1c-e6b6c5075494"
   },
   "source": [
    "Choose the project in which you want to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0805860c-0d65-40c5-bea3-e4fb1ca450c6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project id: 635a5511-72f6-4eb3-8ec6-0763a25e39cb\n",
      "project id: 25fc9237-bda9-42f9-ab83-124bb92b3ae9\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl project list --output json -j \"(resources[].metadata.guid)[0]\" --raw-output\n",
    "# project_id = result.s\n",
    "print(\"project id: {}\".format(project_id))\n",
    "\n",
    "# You can also specify your project id directly:\n",
    "project_id = \"25fc9237-bda9-42f9-ab83-124bb92b3ae9\"\n",
    "print(\"project id: {}\".format(project_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e30a88fa-1c04-4ae5-9142-8c5fddfa3a19"
   },
   "source": [
    "## 2. Demo 1: Creating a notebook asset and running a job <a class=\"anchor\" id=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e67234f6-a7b0-460b-8394-08a73a63f41f"
   },
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62c2b4f6-e3ef-4848-8020-8ff25089f9fd"
   },
   "source": [
    "Suppose you have a Jupyter Notebook (.ipynb) file on your local system and you would like to run the code in the file as a job on a CPD cluster. This section shows you how to create a notebook asset and run a job on a CPD cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0760abc1-28ef-48eb-a884-045d0c724a65"
   },
   "source": [
    "### 2.1 Creating a notebook asset<a class=\"anchor\" id=\"part2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7a01ec2-2d09-407d-9358-8832b1922d76"
   },
   "source": [
    "First of all, you need to create a notebook asset in your project. To create a notebook asset you need to specify:\n",
    "- The environment in which your notebook is to run\n",
    "- A notebook file (.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69ad28e8-4610-4542-9dd6-fb64b479fd55"
   },
   "source": [
    "List all the environments in your project, filter them by their display name and get the ID of the environment in which your notebook will be run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "c5886227-8f4b-4886-9f12-8eddcab8e1ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "environment_name = \"Default Python 3.8\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5ea2ef52-e631-413d-9183-f02fc012d501",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: jupconda38-25fc9237-bda9-42f9-ab83-124bb92b3ae9\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e99cde7c-0156-43a8-940f-e0ec82f1b166"
   },
   "source": [
    "Upload the .ipynb file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7400e787-cbb4-41de-bb46-b16fb7b7a0bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote_file_path = \"notebook/cpdctl-test-notebook.ipynb\"\n",
    "local_file_path = \"Connections-samples.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ad8d535f-08b3-4be1-8b67-2dc01d395dfb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path {remote_file_path} --file {local_file_path} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "959e9a54-89e1-4175-89d6-3f4eaabbb950"
   },
   "source": [
    "Create a notebook asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3691203f-43d1-4583-b31a-701dab3bef24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"cpdctl-test-notebook.ipynb\"\n",
    "runtime = {\n",
    "    'environment': env_id\n",
    "}\n",
    "runtime_json = json.dumps(runtime)\n",
    "originate = {\n",
    "    'type': 'blank'\n",
    "}\n",
    "originate_json = json.dumps(originate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "efc9298e-3f96-44d8-b751-fb94d63b357f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook id: 2b8ccc18-55c4-47dd-b33e-d6b66a760fa8\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook create --file-reference {remote_file_path} --name {file_name} --project {project_id} --runtime '{runtime_json}' --originates-from '{originate_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "notebook_id = result.s\n",
    "print(\"notebook id: {}\".format(notebook_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6116ad92-db26-4356-b560-eaf827a0f6b1"
   },
   "source": [
    "### 2.2 Running a job <a class=\"anchor\" id=\"part2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1224fe1-5db8-4212-8a65-deeeaaf9c037"
   },
   "source": [
    "Before creating a notebook job, you need to create a version of your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "f528b41d-8c6d-4ead-9890-5904ed1447cd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version id: 9bd58f65-80c3-4eb8-b82c-5a49f6f3ef8a\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version create --notebook-id {notebook_id} --output json -j \"metadata.guid\" --raw-output\n",
    "version_id = result.s\n",
    "print(\"version id: {}\".format(version_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1461b0d-bf84-4a65-9881-0ff1f6ab7689"
   },
   "source": [
    "To create a notebook job, you need to give your job a name, add a description, and pass the notebook ID and environment ID you determined in [2.1](#part2.1). Additionally, you can add environment variables that will be used in your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "09daaf3a-1afd-425b-be5b-770d0bfc0b41",
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_name = \"cpdctl-test-job\"\n",
    "job = {\n",
    "    'asset_ref': notebook_id, \n",
    "    'configuration': {\n",
    "        'env_id': env_id, \n",
    "        'env_variables': [\n",
    "            'foo=1', \n",
    "            'bar=2'\n",
    "        ]\n",
    "    }, \n",
    "    'description': 'my job', \n",
    "    'name': job_name\n",
    "}\n",
    "job_json = json.dumps(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3d4b89dc-68fc-4bc6-93c8-7192f5325a46",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job id: 1c0bb5a2-cbb2-4619-91a3-0b8c85b39914\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job create --job '{job_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "job_id = result.s\n",
    "print(\"job id: {}\".format(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b02db7c4-6843-41ab-9c50-390777f243f1"
   },
   "source": [
    "Run a notebook job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "fbdf4d87-f8cf-4c81-8f10-0b47f000b180",
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_run = {\n",
    "    'configuration': {\n",
    "        'env_variables': [\n",
    "            'key1=value1', \n",
    "            'key2=value2'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "job_run_json = json.dumps(job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "8af2ba48-21bf-4f93-a4f6-230497bf1793",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 36971249-e630-4c4f-8050-aab304aa397a\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job run create --project-id {project_id} --job-id {job_id} --job-run '{job_run_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "run_id = result.s\n",
    "print(\"run id: {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "631f6ba3-e981-4efa-860d-dacb8f18c490"
   },
   "source": [
    "You can see the output of each cell in your .ipynb file by listing job run logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "b5ac9c43-6e1d-4336-8935-cf546450c0e0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "Cell 6:\n",
      "\n",
      "Cell 9:\n",
      "cpdctl version: 1.1.132\n",
      "\n",
      "Cell 19:\n",
      "\u001b[1mName\u001b[0m                          \u001b[1mProfile\u001b[0m                       \u001b[1mUser\u001b[0m                       \u001b[1mCurrent\u001b[0m   \n",
      "\u001b[36;1minClusterEnvironmentContext\u001b[0m   inClusterEnvironmentProfile   inClusterEnvironmentUser   *   \n",
      "\n",
      "Cell 21:\n",
      "Switched to context \"inClusterEnvironmentContext\".\n",
      "\n",
      "Cell 23:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                                                \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m                                          \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1m0619c2d3-2b75-42f7-97c1-9d898fdef44c\u001b[0m   Mortgage default project                            2022-02-11T12:02:58.633Z                                                        []   \n",
      "\u001b[36;1m19a29ada-3e9c-4147-bf35-4cf431ed3a26\u001b[0m   AutoAI-TD-Sub                                       2022-01-25T01:20:57.078Z   The classification goal to train a model that can…   []   \n",
      "\u001b[36;1m25fc9237-bda9-42f9-ab83-124bb92b3ae9\u001b[0m   cpdctl-samples-project-notebook-project-test        2022-04-03T15:46:00.738Z                                                        []   \n",
      "\u001b[36;1m2ba058a6-4ef7-4b3b-acde-44baaf288efb\u001b[0m   test-analytics-project-git-ibm-sk-1                 2022-04-01T13:10:46.824Z                                                        []   \n",
      "\u001b[36;1m32d75b88-b113-4bd4-9502-cd2f471a8623\u001b[0m   MLOps-CPD3.0-SWAT-StarterKit-AutoAI-Project-v0.96   2022-01-24T16:02:06.209Z                                                        []   \n",
      "\u001b[36;1m3ea4045c-4ff0-4995-8c80-849d1854b69f\u001b[0m   julian                                              2022-03-30T14:18:22.669Z                                                        []   \n",
      "\u001b[36;1m4aab8ced-62cb-4b13-8708-9883b534c4a6\u001b[0m   test-analytics-project-git-existing-repo            2022-02-11T03:06:38.611Z                                                        []   \n",
      "\u001b[36;1m632cbaf4-f262-45c6-b16b-6746dcc77571\u001b[0m   test-analytics-project-git-ibm-sk-2                 2022-02-15T03:47:31.580Z                                                        []   \n",
      "\u001b[36;1m635a5511-72f6-4eb3-8ec6-0763a25e39cb\u001b[0m   cpdctl-samples-project                              2022-04-03T02:09:06.178Z   cpdctl utility and notebook tutorials sample proj…   []   \n",
      "\u001b[36;1m6d0fa8ad-0b6c-475d-a39e-d672b544d5b6\u001b[0m   MLOps-CPD3.0-SWAT-StarterKit-AutoAI-Project-v0.96   2022-03-29T16:36:07.200Z                                                        []   \n",
      "\n",
      "Cell 25:\n",
      "project id: 0619c2d3-2b75-42f7-97c1-9d898fdef44c\n",
      "\n",
      "Cell 27:\n",
      "project id: 480baa5d-09bc-4853-a323-341d8825c0e9\n",
      "\n",
      "Cell 30:\n",
      "connection id: c4859f1c-80ab-4882-8a24-769505598522\n",
      "\n",
      "Cell 32:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m               \u001b[1mDescription\u001b[0m                  \u001b[1mType\u001b[0m         \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1mc4859f1c-80ab-4882-8a24-769505598522\u001b[0m   cpdctl-test-conn   test connection to aiosdb2   connection   []   \n",
      "\n",
      "Cell 33:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m               \u001b[1mDescription\u001b[0m                  \u001b[1mType\u001b[0m         \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1mc4859f1c-80ab-4882-8a24-769505598522\u001b[0m   cpdctl-test-conn   test connection to aiosdb2   connection   []   \n",
      "\n",
      "Cell 34:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m               \u001b[1mDescription\u001b[0m                  \u001b[1mType\u001b[0m         \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1mc4859f1c-80ab-4882-8a24-769505598522\u001b[0m   cpdctl-test-conn   test connection to aiosdb2   connection   []   \n",
      "\n",
      "Cell 36:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m              \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mprev\u001b[0m          <Nested Object>   \n",
      "\u001b[36;1mtotal_count\u001b[0m   1   \n",
      "\u001b[36;1masset_types\u001b[0m   <Array>   \n",
      "\u001b[36;1massets\u001b[0m        <Array>   \n",
      "\u001b[36;1mfirst\u001b[0m         <Nested Object>   \n",
      "\u001b[36;1mnext\u001b[0m          <Nested Object>   \n",
      "\u001b[36;1mpath\u001b[0m          /DB2INST1   \n",
      "\n",
      "Cell 37:\n",
      "{\n",
      "  \"asset_types\": [\n",
      "    {\n",
      "      \"dataset\": true,\n",
      "      \"dataset_container\": false,\n",
      "      \"type\": \"table\"\n",
      "    }\n",
      "  ],\n",
      "  \"assets\": [\n",
      "    {\n",
      "      \"id\": \"TEST\",\n",
      "      \"name\": \"TEST\",\n",
      "      \"path\": \"/DB2INST1/TEST\",\n",
      "      \"type\": \"table\"\n",
      "    }\n",
      "  ],\n",
      "  \"first\": {\n",
      "    \"href\": \"https://internal-nginx-svc/v2/connections/assets?offset=0\\u0026limit=100\\u0026path=%2FDB2INST1\"\n",
      "  },\n",
      "  \"next\": {\n",
      "    \"href\": \"https://internal-nginx-svc/v2/connections/assets?offset=100\\u0026limit=100\\u0026path=%2FDB2INST1\"\n",
      "  },\n",
      "  \"path\": \"/DB2INST1\",\n",
      "  \"prev\": {\n",
      "    \"href\": \"https://internal-nginx-svc/v2/connections/assets?offset=0\\u0026limit=100\\u0026path=%2FDB2INST1\"\n",
      "  },\n",
      "  \"total_count\": 1\n",
      "}\n",
      "\n",
      "Cell 39:\n",
      "data asset id: e0748869-c723-4ee2-9f95-b48e5c9815ab\n",
      "\n",
      "Cell 41:\n",
      "...\n",
      "\n",
      "\u001b[1mfirst\u001b[0m             \u001b[1mpath\u001b[0m            \u001b[1mtotal_count\u001b[0m   \u001b[1mname\u001b[0m   \u001b[1mtype\u001b[0m   \n",
      "\u001b[36;1m<Nested Object>\u001b[0m   DB2INST1/TEST   1             COL1   <Nested Object>   \n",
      "\u001b[36;1m<Nested Object>\u001b[0m   DB2INST1/TEST   1             COL2   <Nested Object>   \n",
      "\n",
      "Cell 42:\n",
      "{\n",
      "  \"fields\": [\n",
      "    {\n",
      "      \"name\": \"COL1\",\n",
      "      \"type\": {\n",
      "        \"length\": 10,\n",
      "        \"nullable\": true,\n",
      "        \"scale\": 0,\n",
      "        \"signed\": true,\n",
      "        \"type\": \"integer\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"COL2\",\n",
      "      \"type\": {\n",
      "        \"length\": 10,\n",
      "        \"nullable\": true,\n",
      "        \"scale\": 0,\n",
      "        \"signed\": true,\n",
      "        \"type\": \"integer\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"first\": {\n",
      "    \"href\": \"https://internal-nginx-svc/v2/connections/assets/e0748869-c723-4ee2-9f95-b48e5c9815ab?project_id=480baa5d-09bc-4853-a323-341d8825c0e9\\u0026userfs=false\\u0026offset=0\\u0026limit=100\"\n",
      "  },\n",
      "  \"path\": \"DB2INST1/TEST\",\n",
      "  \"total_count\": 1\n",
      "}\n",
      "\n",
      "Cell 44:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m               \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mID:\u001b[0m            c4859f1c-80ab-4882-8a24-769505598522   \n",
      "\u001b[36;1mName:\u001b[0m          cpdctl-test-conn   \n",
      "\u001b[36;1mDescription:\u001b[0m   test connection to aiosdb2   \n",
      "\u001b[36;1mType:\u001b[0m          connection   \n",
      "\u001b[36;1mTags:\u001b[0m          []   \n",
      "\n",
      "Cell 46:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m               \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mName:\u001b[0m          updated-conn-name   \n",
      "\u001b[36;1mDescription:\u001b[0m   test connection to aiosdb2   \n",
      "\u001b[36;1mTags:\u001b[0m          []   \n",
      "\n",
      "Cell 48:\n",
      "...\n",
      "\n",
      "\u001b[1mName\u001b[0m               \u001b[1mDescription\u001b[0m   \n",
      "\u001b[36;1mget_record_count\u001b[0m   Get the number of rows in the specified table   \n",
      "\n",
      "Cell 49:\n",
      "{\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"description\": \"Get the number of rows in the specified table\",\n",
      "      \"name\": \"get_record_count\",\n",
      "      \"properties\": {\n",
      "        \"input\": [\n",
      "          {\n",
      "            \"description\": \"Name of the schema that contains the table\",\n",
      "            \"hidden\": false,\n",
      "            \"label\": \"Schema name\",\n",
      "            \"masked\": false,\n",
      "            \"multiline\": false,\n",
      "            \"name\": \"schema_name\",\n",
      "            \"readonly\": false,\n",
      "            \"required\": false,\n",
      "            \"type\": \"string\",\n",
      "            \"user_defined\": false\n",
      "          },\n",
      "          {\n",
      "            \"description\": \"Name of the table for which to obtain the number of rows\",\n",
      "            \"hidden\": false,\n",
      "            \"label\": \"Table name\",\n",
      "            \"masked\": false,\n",
      "            \"multiline\": false,\n",
      "            \"name\": \"table_name\",\n",
      "            \"readonly\": false,\n",
      "            \"required\": true,\n",
      "            \"type\": \"string\",\n",
      "            \"user_defined\": false\n",
      "          }\n",
      "        ],\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"description\": \"Number of available rows\",\n",
      "            \"hidden\": false,\n",
      "            \"label\": \"Record count\",\n",
      "            \"masked\": false,\n",
      "            \"multiline\": false,\n",
      "            \"name\": \"record_count\",\n",
      "            \"readonly\": false,\n",
      "            \"required\": true,\n",
      "            \"type\": \"integer\",\n",
      "            \"user_defined\": false\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Cell 51:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m               \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mrecord_count\u001b[0m   3   \n",
      "\n",
      "Cell 53:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m              \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mtotal_count\u001b[0m   1   \n",
      "\u001b[36;1masset_types\u001b[0m   <Array>   \n",
      "\u001b[36;1massets\u001b[0m        <Array>   \n",
      "\u001b[36;1mfirst\u001b[0m         <Nested Object>   \n",
      "\u001b[36;1mpath\u001b[0m          /DB2INST1   \n",
      "\n",
      "Cell 54:\n",
      "{\n",
      "  \"asset_types\": [\n",
      "    {\n",
      "      \"dataset\": true,\n",
      "      \"dataset_container\": false,\n",
      "      \"type\": \"table\"\n",
      "    }\n",
      "  ],\n",
      "  \"assets\": [\n",
      "    {\n",
      "      \"id\": \"TEST\",\n",
      "      \"name\": \"TEST\",\n",
      "      \"path\": \"/DB2INST1/TEST\",\n",
      "      \"type\": \"table\"\n",
      "    }\n",
      "  ],\n",
      "  \"first\": {\n",
      "    \"href\": \"https://internal-nginx-svc/v2/connections/c4859f1c-80ab-4882-8a24-769505598522/assets?project_id=480baa5d-09bc-4853-a323-341d8825c0e9\\u0026userfs=false\\u0026offset=0\\u0026limit=100\\u0026path=%2FDB2INST1\"\n",
      "  },\n",
      "  \"path\": \"/DB2INST1\",\n",
      "  \"total_count\": 1\n",
      "}\n",
      "\n",
      "Cell 56:\n",
      "...\n",
      "\n",
      "\u001b[32;1mOK\u001b[0m\n",
      "\n",
      "Cell 58:\n",
      "...\n",
      "\n",
      "\u001b[32;1mOK\u001b[0m\n",
      "\n",
      "Cell 60:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                        \u001b[1mDescription\u001b[0m                                          \u001b[1mType\u001b[0m       \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1m029e5d1c-ba73-4b09-b742-14c3a39b6cf9\u001b[0m   informix                    IBM Informix database                                database   []   \n",
      "\u001b[36;1m048ed1bf-516c-46f0-ae90-fa3349d8bc1c\u001b[0m   postgresql-ibmcloud         Databases for PostgreSQL database                    database   []   \n",
      "\u001b[36;1m05b7f0ea-6ae4-45e2-a455-cc280f110825\u001b[0m   googlecloudstorage          Google Cloud Storage                                 file       []   \n",
      "\u001b[36;1m05c58384-862e-4597-b19a-c71ea7e760bc\u001b[0m   impala                      Cloudera Impala database                             database   []   \n",
      "\u001b[36;1m06847b16-07b4-4415-a924-c63d11a17aa1\u001b[0m   salesforce                  Salesforce.com                                       database   []   \n",
      "\u001b[36;1m0bd5946b-6fcb-4253-bf76-48b362d24a89\u001b[0m   datastax-ibmcloud           DataStax on IBM Cloud database                       database   []   \n",
      "\u001b[36;1m0c431748-2572-11ea-978f-2e728ce88125\u001b[0m   cosmos                      Microsoft Azure Cosmos DB                            file       []   \n",
      "\u001b[36;1m0ca92c3d-0e46-3b42-a573-77958d53c9be\u001b[0m   odbc-datastage              Connection to a database using the ODBC applicati…   database   []   \n",
      "\u001b[36;1m0cd4b64c-b485-47ed-a8c4-329c25412de3\u001b[0m   mysql-compose               Compose for MySQL database                           database   []   \n",
      "\u001b[36;1m0fd83fe5-8995-4e2e-a1be-679bb8813a6d\u001b[0m   hive                        Apache Hive database                                 database   []   \n",
      "\u001b[36;1m11f3029d-a1cf-4c4d-b8e7-64422fa54a94\u001b[0m   cognos-analytics            Cognos Analytics                                     file       []   \n",
      "\u001b[36;1m123e4263-dd25-44e5-8282-cf1b2eeea9bd\u001b[0m   cassandra-datastage         Cassandra Connector for DataStage                    generic    []   \n",
      "\u001b[36;1m13e8b257-1dff-49ed-bac8-7eca796a40b3\u001b[0m   hive-watson                 Hive via Execution Engine for Hadoop                 database   []   \n",
      "\u001b[36;1m193a97c1-4475-4a19-b90c-295c4fdc6517\u001b[0m   bluemixcloudobjectstorage   Cloud Object Storage service on IBM Cloud. Offers…   file       []   \n",
      "\u001b[36;1m200d71ab-24a5-4b3d-85a4-a365bdd0d4cb\u001b[0m   elasticsearch               Elasticsearch                                        file       []   \n",
      "\u001b[36;1m21364ca9-5b2d-323e-bd4d-59ba961f75fb\u001b[0m   webspheremq-datastage       MQ connection                                        database   []   \n",
      "\u001b[36;1m27c3e1b0-b7d2-4e32-9511-1b8aaa197de0\u001b[0m   odata                       OData                                                generic    []   \n",
      "\u001b[36;1m2a7b4fa1-c770-4807-8871-a3c5def5aa2d\u001b[0m   azurefilestorage            Microsoft Azure File Storage                         file       []   \n",
      "\u001b[36;1m2bdd9544-f13a-47b6-b6c3-f5964a08066a\u001b[0m   bigsql                      IBM Db2 Big SQL                                      database   []   \n",
      "\u001b[36;1m2fc1372f-b58c-4d45-b0c4-dfb32a1c78a5\u001b[0m   snowflake                   Snowflake database                                   database   []   \n",
      "\u001b[36;1m31170994-f54c-4148-9c5a-807832fa1d07\u001b[0m   redshift                    Amazon Redshift database                             database   []   \n",
      "\u001b[36;1m335cbfe7-e495-474e-8ad7-78ad63c05091\u001b[0m   db2iseries                  IBM Db2 database for i                               database   []   \n",
      "\u001b[36;1m38714ac2-8f66-4a8c-9b40-806ffb61c759\u001b[0m   generics3                   A storage service compatible with the Amazon S3 A…   file       []   \n",
      "\u001b[36;1m39a78d59-ef34-4108-8e46-4460433a3b99\u001b[0m   dvm                         IBM Data Virtualization Manager for z/OS             database   []   \n",
      "\u001b[36;1m3a00dbd2-2540-4976-afc2-5fc59f68ed35\u001b[0m   salesforce-datastage        Connection to a Salesforce.com enterprise applica…   generic    []   \n",
      "\u001b[36;1m4210c294-8b0f-46b4-bcdc-1c6ada2b7e6b\u001b[0m   http                        Hypertext Transfer Protocol (HTTP)                   file       []   \n",
      "\u001b[36;1m44e904b5-0cb2-4d8e-a5c0-c48bc3e24fdd\u001b[0m   cloudant                    IBM Cloudant                                         file       []   \n",
      "\u001b[36;1m4656c47e-3ada-467e-a541-466c0c55df05\u001b[0m   saphana                     SAP HANA database                                    database   []   \n",
      "\u001b[36;1m48695e79-6279-474a-b539-342625d3dfc2\u001b[0m   sqlserver                   Microsoft SQL Server database                        database   []   \n",
      "\u001b[36;1m49079262-fac2-4762-99d1-452c1caf6b49\u001b[0m   sybaseiq                    SAP IQ database                                      database   []   \n",
      "\u001b[36;1m49686982-255f-423a-a5de-d825bfc0abe3\u001b[0m   dv                          IBM Data Virtualization                              database   []   \n",
      "\u001b[36;1m4bf2dedd-3809-4443-96ec-b7bc5726c07b\u001b[0m   cloudobjectstorage          Object storage for workloads requiring AWS SDKs a…   file       []   \n",
      "\u001b[36;1m506039fb-802f-4ef2-a2bf-c1682e9c8aa2\u001b[0m   db2cloud                    IBM Db2 fully-managed cloud SQL database             database   []   \n",
      "\u001b[36;1m507b850c-f4a1-41d7-ad64-4182a1264014\u001b[0m   dropbox                     Dropbox secure file sharing and storage service      file       []   \n",
      "\u001b[36;1m526f54ea-cde0-4818-a0b6-749efd35ccfa\u001b[0m   impala-watson               Impala via Execution Engine for Hadoop               database   []   \n",
      "\u001b[36;1m63e2d853-e650-3b59-91a5-95e7bf725b9b\u001b[0m   netezza-datastage           Connection to a Netezza Performance Server databa…   database   []   \n",
      "\u001b[36;1m6863060d-97c4-4653-abbe-958bde533f8c\u001b[0m   azuredatalake               Microsoft Azure Data Lake Store via the WebHDFS A…   file       []   \n",
      "\u001b[36;1m693c2a02-39d1-4394-9426-fcdcfc4f3d7a\u001b[0m   googlepubsub                Google Cloud Pub/Sub                                 file       []   \n",
      "\u001b[36;1m6976a3fc-b2ad-4db6-818c-ea049cac309d\u001b[0m   sybase                      SAP ASE database                                     database   []   \n",
      "\u001b[36;1m69857d6b-2be8-4a59-8a70-723405f09708\u001b[0m   looker                      Looker                                               file       []   \n",
      "\u001b[36;1m6bcaf300-30b3-11eb-adc1-0242ac120002\u001b[0m   sqlquery                    IBM SQL Query                                        database   []   \n",
      "\u001b[36;1m79a0a133-cbb6-48d0-a3b0-0956a9655401\u001b[0m   sapodata                    SAP OData                                            generic    []   \n",
      "\u001b[36;1m8136a39f-465f-43a3-a606-ce238fb19116\u001b[0m   exasol                      Exasol database                                      database   []   \n",
      "\u001b[36;1m81641c94-a3a7-4d3e-9ea8-bdf79bdd3b06\u001b[0m   minio                       MinIO                                                file       []   \n",
      "\u001b[36;1m81bafdbd-b7c6-45c5-a4fd-6ec135f66f4e\u001b[0m   assetfiles                  Asset Files                                          file       []   \n",
      "\u001b[36;1m82696f1d-600c-4f78-a03c-d8349ea1976f\u001b[0m   derby                       Apache Derby                                         database   []   \n",
      "\u001b[36;1m83da8a63-ffe3-4aa0-9127-adb5331c19cc\u001b[0m   hdfs-watson                 HDFS via Execution Engine for Hadoop                 file       []   \n",
      "\u001b[36;1m895507b6-f23e-40b2-b40a-5414fc9bd2ca\u001b[0m   hdfs-analyticsengine        IBM Analytics Engine HDFS via the WebHDFS API        file       []   \n",
      "\u001b[36;1m8b8fcd6d-8f95-49c7-8195-c72c95c9a84b\u001b[0m   oracle-amazon               Amazon RDS for Oracle database                       database   []   \n",
      "\u001b[36;1m8c1a4480-1c29-4b33-9086-9cb799d7b157\u001b[0m   db2                         IBM Db2 database                                     database   []   \n",
      "\u001b[36;1m8e65204d-6156-49e7-96e5-d635b2aa05f6\u001b[0m   mongodb-ibmcloud            Databases for MongoDB database                       database   []   \n",
      "\u001b[36;1m933152db-99e1-453a-8ce5-ae0e6714d1a9\u001b[0m   bigquery                    Google BigQuery                                      database   []   \n",
      "\u001b[36;1m9493d830-882b-445e-96c7-8e4c635a1a5b\u001b[0m   postgresql-amazon           Amazon RDS for PostgreSQL database                   database   []   \n",
      "\u001b[36;1m9525f6a6-1c44-4925-b1a0-9a2b731518cb\u001b[0m   db2hosted                   IBM Db2 hosted database                              database   []   \n",
      "\u001b[36;1m96ec8f53-a818-4ba1-bd8d-c86cc33a0b45\u001b[0m   teradata                    Teradata database                                    database   []   \n",
      "\u001b[36;1m971223d3-093e-4957-8af9-a83181ee9dd9\u001b[0m   oracle                      Oracle database                                      database   []   \n",
      "\u001b[36;1m99c3c67b-2133-4006-81f6-2b375a0048a3\u001b[0m   box                         Box file sharing, storage, and collaboration         file       []   \n",
      "\u001b[36;1m9a22e0af-8d19-4c4e-9aea-1d733e81315b\u001b[0m   azureblobstorage            Microsoft Azure Blob Storage                         file       []   \n",
      "\u001b[36;1m9aa630f2-efc4-4d54-b8cb-254f31405b78\u001b[0m   mysql-amazon                Amazon RDS for MySQL database                        database   []   \n",
      "\u001b[36;1m9ebc33eb-8c01-43fd-be1e-7202cf5c2c82\u001b[0m   tableau                     Tableau                                              file       []   \n",
      "\u001b[36;1m9f30e3c3-b854-4144-b5c3-98b7a835dc79\u001b[0m   volumes                     Storage volume                                       file       []   \n",
      "\u001b[36;1ma0b1d14a-4767-404c-aac1-4ce0e62818c3\u001b[0m   amazons3                    Amazon Simple Storage Service (S3)                   file       []   \n",
      "\u001b[36;1me375c0ae-cba9-47fc-baf7-523bef88c09e\u001b[0m   azuresql                    Microsoft Azure SQL Database                         database   []   \n",
      "\u001b[36;1mb2cc3dc2-aff7-4a80-8f80-5e8c5703e9d2\u001b[0m   mysql                       MySQL database                                       database   []   \n",
      "\u001b[36;1mc10e5224-f17d-4524-844f-e97b1305e489\u001b[0m   hdfs-apache                 Apache HDFS via the WebHDFS API                      file       []   \n",
      "\u001b[36;1mc2a82a72-0711-4376-a468-4e9951cabf22\u001b[0m   netezza                     IBM Netezza Performance Server database              database   []   \n",
      "\u001b[36;1mc42bcde4-4345-4fb4-b7da-c8c557527c8b\u001b[0m   db2eventstore               IBM Db2 Event Store                                  database   []   \n",
      "\u001b[36;1mc6fb9293-51eb-4f2b-b20c-4dafa3136744\u001b[0m   mongodb                     MongoDB database                                     database   []   \n",
      "\u001b[36;1mc8d3eab2-25f6-4a90-8e10-0b4226693c45\u001b[0m   db2zos                      IBM Db2 database for z/OS                            database   []   \n",
      "\u001b[36;1mc8f3d379-78b2-4bad-969d-2e928277377e\u001b[0m   tm1odata                    Planning Analytics                                   generic    []   \n",
      "\u001b[36;1me6ff8c10-4199-4b58-9a93-749411eafacd\u001b[0m   cassandra                   Apache Cassandra database                            database   []   \n",
      "\u001b[36;1mcfdcb449-1204-44ba-baa6-9a8a878e6aa7\u001b[0m   dashdb                      Db2 Warehouse                                        database   []   \n",
      "\u001b[36;1md5dbc62f-7c4c-4d49-8eb2-dab6cef2969c\u001b[0m   ftp                         Remote file system (FTP)                             file       []   \n",
      "\u001b[36;1mfa31fba9-10e9-32d7-968c-f677fffd1e3b\u001b[0m   db2-datastage               Connection to a Db2 database for the DataStage 'D…   database   []   \n",
      "\u001b[36;1mdd22f798-8c9b-41fa-841e-d66cbdf50722\u001b[0m   oracle-datastage            Connection to an Oracle database for the DataStag…   generic    []   \n",
      "\u001b[36;1me1c23729-99d8-4407-b3df-336e33ffdc82\u001b[0m   postgresql                  PostgreSQL database                                  database   []   \n",
      "\u001b[36;1me278eff1-a7c4-4d60-9a02-bde1bb1d26ef\u001b[0m   greenplum                   Greenplum database                                   database   []   \n",
      "\u001b[36;1me59b1c36-6f30-4879-9f74-7e81dde4cca6\u001b[0m   genericjdbc                 Generic JDBC database                                database   []   \n",
      "\u001b[36;1mf13bc9b7-4a46-48f4-99c3-01d943334ba7\u001b[0m   kafka-datastage             Connection to an Apache Kafka real-time processin…   generic    []   \n",
      "\u001b[36;1mf3ee04c2-7c3b-4534-b300-eb6ef701646d\u001b[0m   mariadb                     MariaDB                                              database   []   \n",
      "\u001b[36;1mfc183fe5-cfe7-40a5-b473-e23ca025f05f\u001b[0m   spss                        IBM SPSS Analytic Server                             database   []   \n",
      "\n",
      "Cell 61:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m               \u001b[1mDescription\u001b[0m                                          \u001b[1mType\u001b[0m   \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1ma0b1d14a-4767-404c-aac1-4ce0e62818c3\u001b[0m   amazons3           Amazon Simple Storage Service (S3)                   file   []   \n",
      "\u001b[36;1m81bafdbd-b7c6-45c5-a4fd-6ec135f66f4e\u001b[0m   assetfiles         Asset Files                                          file   []   \n",
      "\u001b[36;1m9a22e0af-8d19-4c4e-9aea-1d733e81315b\u001b[0m   azureblobstorage   Microsoft Azure Blob Storage                         file   []   \n",
      "\u001b[36;1m6863060d-97c4-4653-abbe-958bde533f8c\u001b[0m   azuredatalake      Microsoft Azure Data Lake Store via the WebHDFS A…   file   []   \n",
      "\u001b[36;1m2a7b4fa1-c770-4807-8871-a3c5def5aa2d\u001b[0m   azurefilestorage   Microsoft Azure File Storage                         file   []   \n",
      "Next token: 'https://internal-nginx-svc/v2/datasource_types?offset=5&limit=5&sort=entity.name'\n",
      "\n",
      "Cell 62:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m               \u001b[1mDescription\u001b[0m                       \u001b[1mType\u001b[0m       \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1m0fd83fe5-8995-4e2e-a1be-679bb8813a6d\u001b[0m   hive               Apache Hive database              database   []   \n",
      "\u001b[36;1m48695e79-6279-474a-b539-342625d3dfc2\u001b[0m   sqlserver          Microsoft SQL Server database     database   []   \n",
      "\u001b[36;1m6bcaf300-30b3-11eb-adc1-0242ac120002\u001b[0m   sqlquery           IBM SQL Query                     database   []   \n",
      "\u001b[36;1m8b8fcd6d-8f95-49c7-8195-c72c95c9a84b\u001b[0m   oracle-amazon      Amazon RDS for Oracle database    database   []   \n",
      "\u001b[36;1m8c1a4480-1c29-4b33-9086-9cb799d7b157\u001b[0m   db2                IBM Db2 database                  database   []   \n",
      "\u001b[36;1m8e65204d-6156-49e7-96e5-d635b2aa05f6\u001b[0m   mongodb-ibmcloud   Databases for MongoDB database    database   []   \n",
      "\u001b[36;1m971223d3-093e-4957-8af9-a83181ee9dd9\u001b[0m   oracle             Oracle database                   database   []   \n",
      "\u001b[36;1mc10e5224-f17d-4524-844f-e97b1305e489\u001b[0m   hdfs-apache        Apache HDFS via the WebHDFS API   file       []   \n",
      "\u001b[36;1mc6fb9293-51eb-4f2b-b20c-4dafa3136744\u001b[0m   mongodb            MongoDB database                  database   []   \n",
      "\u001b[36;1mcfdcb449-1204-44ba-baa6-9a8a878e6aa7\u001b[0m   dashdb             Db2 Warehouse                     database   []   \n",
      "\u001b[36;1me59b1c36-6f30-4879-9f74-7e81dde4cca6\u001b[0m   genericjdbc        Generic JDBC database             database   []   \n",
      "\n",
      "Cell 63:\n",
      "...\n",
      "\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                        \u001b[1mDescription\u001b[0m                                          \u001b[1mType\u001b[0m       \u001b[1mTags\u001b[0m   \n",
      "\u001b[36;1m029e5d1c-ba73-4b09-b742-14c3a39b6cf9\u001b[0m   informix                    IBM Informix database                                database   []   \n",
      "\u001b[36;1m048ed1bf-516c-46f0-ae90-fa3349d8bc1c\u001b[0m   postgresql-ibmcloud         Databases for PostgreSQL database                    database   []   \n",
      "\u001b[36;1m05b7f0ea-6ae4-45e2-a455-cc280f110825\u001b[0m   googlecloudstorage          Google Cloud Storage                                 file       []   \n",
      "\u001b[36;1m05c58384-862e-4597-b19a-c71ea7e760bc\u001b[0m   impala                      Cloudera Impala database                             database   []   \n",
      "\u001b[36;1m06847b16-07b4-4415-a924-c63d11a17aa1\u001b[0m   salesforce                  Salesforce.com                                       database   []   \n",
      "\u001b[36;1m0bd5946b-6fcb-4253-bf76-48b362d24a89\u001b[0m   datastax-ibmcloud           DataStax on IBM Cloud database                       database   []   \n",
      "\u001b[36;1m0c431748-2572-11ea-978f-2e728ce88125\u001b[0m   cosmos                      Microsoft Azure Cosmos DB                            file       []   \n",
      "\u001b[36;1m0ca92c3d-0e46-3b42-a573-77958d53c9be\u001b[0m   odbc-datastage              Connection to a database using the ODBC applicati…   database   []   \n",
      "\u001b[36;1m0cd4b64c-b485-47ed-a8c4-329c25412de3\u001b[0m   mysql-compose               Compose for MySQL database                           database   []   \n",
      "\u001b[36;1m0fd83fe5-8995-4e2e-a1be-679bb8813a6d\u001b[0m   hive                        Apache Hive database                                 database   []   \n",
      "\u001b[36;1m11f3029d-a1cf-4c4d-b8e7-64422fa54a94\u001b[0m   cognos-analytics            Cognos Analytics                                     file       []   \n",
      "\u001b[36;1m123e4263-dd25-44e5-8282-cf1b2eeea9bd\u001b[0m   cassandra-datastage         Cassandra Connector for DataStage                    generic    []   \n",
      "\u001b[36;1m13e8b257-1dff-49ed-bac8-7eca796a40b3\u001b[0m   hive-watson                 Hive via Execution Engine for Hadoop                 database   []   \n",
      "\u001b[36;1m193a97c1-4475-4a19-b90c-295c4fdc6517\u001b[0m   bluemixcloudobjectstorage   Cloud Object Storage service on IBM Cloud. Offers…   file       []   \n",
      "\u001b[36;1m200d71ab-24a5-4b3d-85a4-a365bdd0d4cb\u001b[0m   elasticsearch               Elasticsearch                                        file       []   \n",
      "\u001b[36;1m21364ca9-5b2d-323e-bd4d-59ba961f75fb\u001b[0m   webspheremq-datastage       MQ connection                                        database   []   \n",
      "\u001b[36;1m27c3e1b0-b7d2-4e32-9511-1b8aaa197de0\u001b[0m   odata                       OData                                                generic    []   \n",
      "\u001b[36;1m2a7b4fa1-c770-4807-8871-a3c5def5aa2d\u001b[0m   azurefilestorage            Microsoft Azure File Storage                         file       []   \n",
      "\u001b[36;1m2bdd9544-f13a-47b6-b6c3-f5964a08066a\u001b[0m   bigsql                      IBM Db2 Big SQL                                      database   []   \n",
      "\u001b[36;1m2fc1372f-b58c-4d45-b0c4-dfb32a1c78a5\u001b[0m   snowflake                   Snowflake database                                   database   []   \n",
      "\u001b[36;1m31170994-f54c-4148-9c5a-807832fa1d07\u001b[0m   redshift                    Amazon Redshift database                             database   []   \n",
      "\u001b[36;1m335cbfe7-e495-474e-8ad7-78ad63c05091\u001b[0m   db2iseries                  IBM Db2 database for i                               database   []   \n",
      "\u001b[36;1m38714ac2-8f66-4a8c-9b40-806ffb61c759\u001b[0m   generics3                   A storage service compatible with the Amazon S3 A…   file       []   \n",
      "\u001b[36;1m39a78d59-ef34-4108-8e46-4460433a3b99\u001b[0m   dvm                         IBM Data Virtualization Manager for z/OS             database   []   \n",
      "\u001b[36;1m3a00dbd2-2540-4976-afc2-5fc59f68ed35\u001b[0m   salesforce-datastage        Connection to a Salesforce.com enterprise applica…   generic    []   \n",
      "\u001b[36;1m4210c294-8b0f-46b4-bcdc-1c6ada2b7e6b\u001b[0m   http                        Hypertext Transfer Protocol (HTTP)                   file       []   \n",
      "\u001b[36;1m44e904b5-0cb2-4d8e-a5c0-c48bc3e24fdd\u001b[0m   cloudant                    IBM Cloudant                                         file       []   \n",
      "\u001b[36;1m4656c47e-3ada-467e-a541-466c0c55df05\u001b[0m   saphana                     SAP HANA database                                    database   []   \n",
      "\u001b[36;1m48695e79-6279-474a-b539-342625d3dfc2\u001b[0m   sqlserver                   Microsoft SQL Server database                        database   []   \n",
      "\u001b[36;1m49079262-fac2-4762-99d1-452c1caf6b49\u001b[0m   sybaseiq                    SAP IQ database                                      database   []   \n",
      "\u001b[36;1m49686982-255f-423a-a5de-d825bfc0abe3\u001b[0m   dv                          IBM Data Virtualization                              database   []   \n",
      "\u001b[36;1m4bf2dedd-3809-4443-96ec-b7bc5726c07b\u001b[0m   cloudobjectstorage          Object storage for workloads requiring AWS SDKs a…   file       []   \n",
      "\u001b[36;1m506039fb-802f-4ef2-a2bf-c1682e9c8aa2\u001b[0m   db2cloud                    IBM Db2 fully-managed cloud SQL database             database   []   \n",
      "\u001b[36;1m507b850c-f4a1-41d7-ad64-4182a1264014\u001b[0m   dropbox                     Dropbox secure file sharing and storage service      file       []   \n",
      "\u001b[36;1m526f54ea-cde0-4818-a0b6-749efd35ccfa\u001b[0m   impala-watson               Impala via Execution Engine for Hadoop               database   []   \n",
      "\u001b[36;1m63e2d853-e650-3b59-91a5-95e7bf725b9b\u001b[0m   netezza-datastage           Connection to a Netezza Performance Server databa…   database   []   \n",
      "\u001b[36;1m6863060d-97c4-4653-abbe-958bde533f8c\u001b[0m   azuredatalake               Microsoft Azure Data Lake Store via the WebHDFS A…   file       []   \n",
      "\u001b[36;1m693c2a02-39d1-4394-9426-fcdcfc4f3d7a\u001b[0m   googlepubsub                Google Cloud Pub/Sub                                 file       []   \n",
      "\u001b[36;1m6976a3fc-b2ad-4db6-818c-ea049cac309d\u001b[0m   sybase                      SAP ASE database                                     database   []   \n",
      "\u001b[36;1m69857d6b-2be8-4a59-8a70-723405f09708\u001b[0m   looker                      Looker                                               file       []   \n",
      "\u001b[36;1m6bcaf300-30b3-11eb-adc1-0242ac120002\u001b[0m   sqlquery                    IBM SQL Query                                        database   []   \n",
      "\u001b[36;1m79a0a133-cbb6-48d0-a3b0-0956a9655401\u001b[0m   sapodata                    SAP OData                                            generic    []   \n",
      "\u001b[36;1m8136a39f-465f-43a3-a606-ce238fb19116\u001b[0m   exasol                      Exasol database                                      database   []   \n",
      "\u001b[36;1m81641c94-a3a7-4d3e-9ea8-bdf79bdd3b06\u001b[0m   minio                       MinIO                                                file       []   \n",
      "\u001b[36;1m81bafdbd-b7c6-45c5-a4fd-6ec135f66f4e\u001b[0m   assetfiles                  Asset Files                                          file       []   \n",
      "\u001b[36;1m82696f1d-600c-4f78-a03c-d8349ea1976f\u001b[0m   derby                       Apache Derby                                         database   []   \n",
      "\u001b[36;1m83da8a63-ffe3-4aa0-9127-adb5331c19cc\u001b[0m   hdfs-watson                 HDFS via Execution Engine for Hadoop                 file       []   \n",
      "\u001b[36;1m895507b6-f23e-40b2-b40a-5414fc9bd2ca\u001b[0m   hdfs-analyticsengine        IBM Analytics Engine HDFS via the WebHDFS API        file       []   \n",
      "\u001b[36;1m8b8fcd6d-8f95-49c7-8195-c72c95c9a84b\u001b[0m   oracle-amazon               Amazon RDS for Oracle database                       database   []   \n",
      "\u001b[36;1m8c1a4480-1c29-4b33-9086-9cb799d7b157\u001b[0m   db2                         IBM Db2 database                                     database   []   \n",
      "\u001b[36;1m8e65204d-6156-49e7-96e5-d635b2aa05f6\u001b[0m   mongodb-ibmcloud            Databases for MongoDB database                       database   []   \n",
      "\u001b[36;1m933152db-99e1-453a-8ce5-ae0e6714d1a9\u001b[0m   bigquery                    Google BigQuery                                      database   []   \n",
      "\u001b[36;1m9493d830-882b-445e-96c7-8e4c635a1a5b\u001b[0m   postgresql-amazon           Amazon RDS for PostgreSQL database                   database   []   \n",
      "\u001b[36;1m9525f6a6-1c44-4925-b1a0-9a2b731518cb\u001b[0m   db2hosted                   IBM Db2 hosted database                              database   []   \n",
      "\u001b[36;1m96ec8f53-a818-4ba1-bd8d-c86cc33a0b45\u001b[0m   teradata                    Teradata database                                    database   []   \n",
      "\u001b[36;1m971223d3-093e-4957-8af9-a83181ee9dd9\u001b[0m   oracle                      Oracle database                                      database   []   \n",
      "\u001b[36;1m99c3c67b-2133-4006-81f6-2b375a0048a3\u001b[0m   box                         Box file sharing, storage, and collaboration         file       []   \n",
      "\u001b[36;1m9a22e0af-8d19-4c4e-9aea-1d733e81315b\u001b[0m   azureblobstorage            Microsoft Azure Blob Storage                         file       []   \n",
      "\u001b[36;1m9aa630f2-efc4-4d54-b8cb-254f31405b78\u001b[0m   mysql-amazon                Amazon RDS for MySQL database                        database   []   \n",
      "\u001b[36;1m9ebc33eb-8c01-43fd-be1e-7202cf5c2c82\u001b[0m   tableau                     Tableau                                              file       []   \n",
      "\u001b[36;1m9f30e3c3-b854-4144-b5c3-98b7a835dc79\u001b[0m   volumes                     Storage volume                                       file       []   \n",
      "\u001b[36;1ma0b1d14a-4767-404c-aac1-4ce0e62818c3\u001b[0m   amazons3                    Amazon Simple Storage Service (S3)                   file       []   \n",
      "\u001b[36;1me375c0ae-cba9-47fc-baf7-523bef88c09e\u001b[0m   azuresql                    Microsoft Azure SQL Database                         database   []   \n",
      "\u001b[36;1mb2cc3dc2-aff7-4a80-8f80-5e8c5703e9d2\u001b[0m   mysql                       MySQL database                                       database   []   \n",
      "\u001b[36;1mc10e5224-f17d-4524-844f-e97b1305e489\u001b[0m   hdfs-apache                 Apache HDFS via the WebHDFS API                      file       []   \n",
      "\u001b[36;1mc2a82a72-0711-4376-a468-4e9951cabf22\u001b[0m   netezza                     IBM Netezza Performance Server database              database   []   \n",
      "\u001b[36;1mc42bcde4-4345-4fb4-b7da-c8c557527c8b\u001b[0m   db2eventstore               IBM Db2 Event Store                                  database   []   \n",
      "\u001b[36;1mc6fb9293-51eb-4f2b-b20c-4dafa3136744\u001b[0m   mongodb                     MongoDB database                                     database   []   \n",
      "\u001b[36;1mc8d3eab2-25f6-4a90-8e10-0b4226693c45\u001b[0m   db2zos                      IBM Db2 database for z/OS                            database   []   \n",
      "\u001b[36;1mc8f3d379-78b2-4bad-969d-2e928277377e\u001b[0m   tm1odata                    Planning Analytics                                   generic    []   \n",
      "\u001b[36;1me6ff8c10-4199-4b58-9a93-749411eafacd\u001b[0m   cassandra                   Apache Cassandra database                            database   []   \n",
      "\u001b[36;1mcfdcb449-1204-44ba-baa6-9a8a878e6aa7\u001b[0m   dashdb                      Db2 Warehouse                                        database   []   \n",
      "\u001b[36;1md5dbc62f-7c4c-4d49-8eb2-dab6cef2969c\u001b[0m   ftp                         Remote file system (FTP)                             file       []   \n",
      "\u001b[36;1mfa31fba9-10e9-32d7-968c-f677fffd1e3b\u001b[0m   db2-datastage               Connection to a Db2 database for the DataStage 'D…   database   []   \n",
      "\u001b[36;1mdd22f798-8c9b-41fa-841e-d66cbdf50722\u001b[0m   oracle-datastage            Connection to an Oracle database for the DataStag…   generic    []   \n",
      "\u001b[36;1me1c23729-99d8-4407-b3df-336e33ffdc82\u001b[0m   postgresql                  PostgreSQL database                                  database   []   \n",
      "\u001b[36;1me278eff1-a7c4-4d60-9a02-bde1bb1d26ef\u001b[0m   greenplum                   Greenplum database                                   database   []   \n",
      "\u001b[36;1me59b1c36-6f30-4879-9f74-7e81dde4cca6\u001b[0m   genericjdbc                 Generic JDBC database                                database   []   \n",
      "\u001b[36;1mf13bc9b7-4a46-48f4-99c3-01d943334ba7\u001b[0m   kafka-datastage             Connection to an Apache Kafka real-time processin…   generic    []   \n",
      "\u001b[36;1mf3ee04c2-7c3b-4534-b300-eb6ef701646d\u001b[0m   mariadb                     MariaDB                                              database   []   \n",
      "\u001b[36;1mfc183fe5-cfe7-40a5-b473-e23ca025f05f\u001b[0m   spss                        IBM SPSS Analytic Server                             database   []   \n",
      "\n",
      "Cell 65:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m               \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mID:\u001b[0m            cfdcb449-1204-44ba-baa6-9a8a878e6aa7   \n",
      "\u001b[36;1mName:\u001b[0m          dashdb   \n",
      "\u001b[36;1mDescription:\u001b[0m   Db2 Warehouse   \n",
      "\u001b[36;1mType:\u001b[0m          database   \n",
      "\u001b[36;1mTags:\u001b[0m          []   \n",
      "\n",
      "Cell 66:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m               \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mID:\u001b[0m            cfdcb449-1204-44ba-baa6-9a8a878e6aa7   \n",
      "\u001b[36;1mName:\u001b[0m          dashdb   \n",
      "\u001b[36;1mDescription:\u001b[0m   Db2 Warehouse   \n",
      "\u001b[36;1mType:\u001b[0m          database   \n",
      "\u001b[36;1mTags:\u001b[0m          []   \n",
      "\n",
      "Cell 67:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m               \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mID:\u001b[0m            8c1a4480-1c29-4b33-9086-9cb799d7b157   \n",
      "\u001b[36;1mName:\u001b[0m          db2   \n",
      "\u001b[36;1mDescription:\u001b[0m   IBM Db2 database   \n",
      "\u001b[36;1mType:\u001b[0m          database   \n",
      "\u001b[36;1mTags:\u001b[0m          []   \n",
      "\n",
      "Cell 68:\n",
      "...\n",
      "\n",
      "\u001b[1m\u001b[0m               \u001b[1m\u001b[0m   \n",
      "\u001b[36;1mID:\u001b[0m            8c1a4480-1c29-4b33-9086-9cb799d7b157   \n",
      "\u001b[36;1mName:\u001b[0m          db2   \n",
      "\u001b[36;1mDescription:\u001b[0m   IBM Db2 database   \n",
      "\u001b[36;1mType:\u001b[0m          database   \n",
      "\u001b[36;1mTags:\u001b[0m          []   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cpdctl job run logs --job-id {job_id} --run-id {run_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a6d9631-a0b1-4e7f-ac05-8bfe60904f33"
   },
   "source": [
    "## 3. Demo 2: Creating a Python script asset and running a job <a class=\"anchor\" id=\"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a690f528-3bb5-4c67-a665-c74452c30c28"
   },
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d88bc51f-29cd-4055-a52e-356f14a0c20f"
   },
   "source": [
    "Suppose you have a Python script (.py) on your local system and you would like to run the code in the script as a job on a CPD cluster. This section shows you how to create a Python script asset and run a job on a CPD cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "209c28e9-0376-4f23-b851-53ed18ba77cf"
   },
   "source": [
    "### 3.1 Creating a Python script asset<a class=\"anchor\" id=\"part3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9790b77-a1e6-4b78-9f48-6c31a758dfef"
   },
   "source": [
    "Upload the script (.py) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "4df988f8-c5df-4218-9441-acaa06ed2a13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote_file_path = \"script/test_script.py\"\n",
    "local_file_path = \"test_script.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "f642dbbb-8726-4c9e-9767-bec61a3cb3ae",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path {remote_file_path} --file {local_file_path} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beb39207-813b-4bc9-81f5-f5e70eaaceb3"
   },
   "source": [
    "Specify the metadata, entity and attachments of the script file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "898bcf0c-c019-47a7-8039-ebca4f1e1d49",
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"name\": \"my_test_script\",\n",
    "    \"asset_type\": \"script\",\n",
    "    \"asset_category\": \"USER\",\n",
    "    \"origin_country\": \"us\"\n",
    "}\n",
    "metadata_json = json.dumps(metadata)\n",
    "\n",
    "entity = {\n",
    "    \"script\": {\n",
    "        \"language\": {\n",
    "            \"name\": \"python3\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "entity_json = json.dumps(entity)\n",
    "\n",
    "attachments = [\n",
    "    {\n",
    "        \"asset_type\": \"script\",\n",
    "        \"name\": \"my_test_script\",\n",
    "        \"description\": \"attachment for script\",\n",
    "        \"mime\": \"application/text\",\n",
    "        \"object_key\": remote_file_path\n",
    "    }\n",
    "]\n",
    "attachments_json = json.dumps(attachments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "941c66ab-dbcb-4698-9be0-0c85080adc50"
   },
   "source": [
    "Create a Python script asset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "be3d4868-1fb2-426b-a3c9-50e1ca860d4a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script id: 991b7c56-5d07-4ef6-8681-e4d86e462a3b\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl asset create  --metadata '{metadata_json}' --entity '{entity_json}' --attachments '{attachments_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "script_id = result.s\n",
    "print(\"script id: {}\".format(script_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77d5ed01-5032-42d7-a94a-b1df82794780"
   },
   "source": [
    "### 3.2 Running a job<a class=\"anchor\" id=\"part3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b5b2b4e-e81c-4cfb-beb6-2d78f1df00c3"
   },
   "source": [
    "Similar to a notebook job, you need to specify the environment in which your script job is to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "98ecd0ec-a07d-45ba-b324-9344674ab5a6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "environment_name = \"Default Python 3.8\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "56d3dc99-4c75-4801-bd19-6374124c0526",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: jupconda38-25fc9237-bda9-42f9-ab83-124bb92b3ae9\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3773018b-ce6a-4ccd-ad15-0c17e9af5bbc"
   },
   "source": [
    "Now you can create a script job. To do this, you need to give your script job a name, a description, and pass the script ID and environment ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "7500ac92-d064-42b1-8871-7ac7fa8a64c8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_name = \"cpdctl-test-job-for-script\"\n",
    "job = {\n",
    "    'asset_ref': script_id, \n",
    "    'configuration': {\n",
    "        'env_id': env_id, \n",
    "        'env_variables': [\n",
    "            'foo=1', \n",
    "            'bar=2'\n",
    "        ]\n",
    "    }, \n",
    "    'description': 'my script job', \n",
    "    'name': job_name\n",
    "}\n",
    "job_json = json.dumps(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "f970393a-7bbb-43c4-8cb9-866374d45611",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job id: 204f994d-512a-4af1-bcc1-97f636340648\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job create --job '{job_json}' --project-id {project_id} --output json -j \"metadata.asset_id\" --raw-output\n",
    "job_id = result.s\n",
    "print(\"job id: {}\".format(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "359ba962-bb9b-40c4-9714-3dff23bb36b1"
   },
   "source": [
    "Run your script job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "a5ab660c-6370-48c2-bbd3-66a86dc0f950",
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_run = {\n",
    "    'configuration': {\n",
    "        'env_variables': [\n",
    "            'key1=value1', \n",
    "            'key2=value2'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "job_run_json = json.dumps(job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "7350c902-9eac-4b37-9229-4543b5498ec3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: b8569a50-de46-4ef7-936d-dba0c72d6511\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl job run create --project-id {project_id} --job-id {job_id} --job-run '{job_run_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "run_id = result.s\n",
    "print(\"run id: {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5553338d-0ffd-4927-b018-af7b3b637313"
   },
   "source": [
    "Show your script job run logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "36189b2e-b0af-4cc8-8f2e-ca39a93a86e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "HelloCP4D 4.0.6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! cpdctl job run logs --job-id {job_id} --run-id {run_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "217c063f-a014-462d-84e0-03a565c5ba47"
   },
   "source": [
    "## 4. Demo 3: Downloading a notebook and uploading it to another project <a class=\"anchor\" id=\"part4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb0705f9-7dc7-48f3-8e4b-f18f9d1607ea"
   },
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c03e0ba-f595-4466-ad54-017b4bc862f1"
   },
   "source": [
    "Suppose you have a notebook in one project and would like to add a specific version of this notebook to another project. To do this, you first need to download the notebook file to your local system and then upload it to the other project. After that you need to create a notebook asset in your project by referencing the uploaded notebook file (.ipynb) and specifying the environment in which your notebook is to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52158a7e-2814-4d6a-a0fd-1ddbf28224a0"
   },
   "source": [
    "### 4.1 Downloading a notebook <a class=\"anchor\" id=\"part4.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df873b46-7c6c-4ebe-bc64-5c1948cb8beb"
   },
   "source": [
    "You can select which notebook version you want to download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c6996c4-d3df-4679-b117-a9fd8b4dc334"
   },
   "source": [
    "List notebook versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "70771bfa-b46a-4b88-8bc5-7e6cdb5fdb24",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mCreated\u001b[0m   \n",
      "\u001b[36;1m9bd58f65-80c3-4eb8-b82c-5a49f6f3ef8a\u001b[0m   1649002300317   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl notebook version list --notebook-id {notebook_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8b019c8-cda2-4ecd-933f-a4f733fc45d9"
   },
   "source": [
    "Get the path in the storage volume to the notebook version that you want to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "f01a8b58-2770-4490-91ce-290774e7f2a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version id: 9bd58f65-80c3-4eb8-b82c-5a49f6f3ef8a\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version list --notebook-id {notebook_id} --output json -j \"(resources[].metadata.guid)[0]\" --raw-output\n",
    "version_id = result.s\n",
    "print(\"version id: {}\".format(version_id))\n",
    "\n",
    "# You can also specify your version id directly:\n",
    "# env_id = \"Your version ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "4153c574-091b-404e-8eb1-a99f6863b76a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version storage path: notebook/attachment_for_notebook_2b8ccc18_55c4_47dd_b33e_d6b66a760fa8_7cibhro27aps0wqp1z4va9eze.ipynb\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook version get --notebook-id {notebook_id} --version-id {version_id} --output json -j \"entity.file_reference\" --raw-output\n",
    "version_storage_path = result.s\n",
    "print(\"version storage path: {}\".format(version_storage_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2948753-bb4d-4d65-9b61-cdfc5e7a2b2d"
   },
   "source": [
    "Download the noteboook asset with the specific version from the storage path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "0a79838e-2db6-4d96-85ad-ba0326e530b4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n",
      "Output written to my-new-notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "file_name = \"my-new-notebook.ipynb\"\n",
    "\n",
    "! cpdctl asset file download --path {version_storage_path} --output-file {file_name} --project-id {project_id} --raw-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a640b234-811c-4670-878c-fad1e0803dfe"
   },
   "source": [
    "### 4.2 Uploading the notebook to another project <a class=\"anchor\" id=\"part4.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e97c68d-5ccd-49f9-aa16-de3dc8108aea"
   },
   "source": [
    "Determine the ID of the project to which you want to upload your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "85e41838-4ec0-4412-b051-3ba2aa239cce",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another project id: 19a29ada-3e9c-4147-bf35-4cf431ed3a26\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl project list --output json -j \"(resources[].metadata.guid)[1]\" --raw-output\n",
    "project2_id = result.s\n",
    "print(\"another project id: {}\".format(project2_id))\n",
    "\n",
    "# You can also specify your another project id directly:\n",
    "# project2_id = \"Your another project ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e56ffaf-af0a-466b-94c2-0c8d829be2f3"
   },
   "source": [
    "Upload the notebook file to this project: my project: AutoAI-TD-Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "64772a05-c612-4b81-9d04-51129cf9c547",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "remote_file_path = \"notebook/{}\".format(file_name)\n",
    "\n",
    "! cpdctl asset file upload --path {remote_file_path} --file {file_name} --project-id {project2_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3d7db4c-1dc5-4b46-a4b9-a5dd45b76b08"
   },
   "source": [
    "After you have uploaded the notebook file to the project, you need to specify the environment in which to run the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "7feb5a69-790e-44ea-83ac-34491fa48de2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "environment_name = \"Default Python 3.8\"\n",
    "query_string = \"(resources[?entity.environment.display_name == '{}'].metadata.asset_id)[0]\".format(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "9af4cafa-8979-4ef0-8e40-efd64421a9e4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment id: jupconda38-19a29ada-3e9c-4147-bf35-4cf431ed3a26\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment list --project-id {project2_id} --output json -j \"{query_string}\" --raw-output\n",
    "env_id = result.s\n",
    "print(\"environment id: {}\".format(env_id))\n",
    "\n",
    "# You can also specify your environment id directly:\n",
    "# env_id = \"Your environment ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "831352d0-dd22-4861-a109-2f92f75f160e"
   },
   "source": [
    "Now you can create a notebook asset in this project by referencing the uploaded notebook file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "43663810-c448-418a-90be-a822c3f43fa2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"my-new-notebook-in-another-project.ipynb\"\n",
    "runtime = {\n",
    "    'environment': env_id\n",
    "}\n",
    "runtime_json = json.dumps(runtime)\n",
    "originate = {\n",
    "    'type': 'blank'\n",
    "}\n",
    "originate_json = json.dumps(originate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "a047ccf0-8b16-4a9e-bfe5-e22c4a9af1c0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook id: 1b14155a-6705-40a1-ab6c-622be556e584\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl notebook create --file-reference {remote_file_path} --name {file_name} --project {project2_id} --originates-from '{originate_json}' --runtime '{runtime_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "notebook_id = result.s\n",
    "print(\"notebook id: {}\".format(notebook_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95206295-0293-451b-aa0b-d881447d1a8b"
   },
   "source": [
    "## 5. Demo 4: Adding additional packages for custom environment <a class=\"anchor\" id=\"part5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd302c88-f6ee-4b47-a325-d86b7a814837"
   },
   "source": [
    "Before starting with this section, ensure that you have run the cells in [Section 1](#part1) and specified the ID of the project in which you will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30b8f0fd-2216-4dc2-b347-c1a49c08ec1a"
   },
   "source": [
    "Suppose you have a `conda-yml` file that lists your additional packages **or** you have a `pip-zip` file containing your custom packages, and you would like to install these packages in your custom environment. To do this, you need to:\n",
    "\n",
    "- Create a custom software specification\n",
    "- Add your custom packages\n",
    "- Create a custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12bcb74b-e9ad-4f4d-abb5-d97773e4730c"
   },
   "source": [
    "### 5.1 Creating a custom software specification <a class=\"anchor\" id=\"part5.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a348d9b-da7f-431d-aa41-2b04bfefe9fa"
   },
   "source": [
    "To create a custom software specification, you need to specify the base software specification that you want to customize. You can list all the software specifications in your project and choose one of them as the base software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "8f11cde3-0b5f-4a04-acbb-858c92a0f0aa",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m                            \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m                                          \u001b[1mType\u001b[0m   \n",
      "\u001b[36;1m0062b8c9-8b7d-44a0-a9b9-46c416adcbd9\u001b[0m   default_py3.6                   2022-01-17T22:11:48.813Z   Default Python 3.6                                   software_specification   \n",
      "\u001b[36;1m069ea134-3346-5748-b513-49120e15d288\u001b[0m   pytorch-onnx_1.3-py3.7-edt      2022-01-17T22:11:48.823Z   Software specification for Pytorch 1.3.1 Elastic …   software_specification   \n",
      "\u001b[36;1m09c5a1d0-9c1e-4473-a344-eb7b665ff687\u001b[0m   scikit-learn_0.20-py3.6         2022-01-17T22:11:48.815Z   Software specification for Scikit-learn on Python…   software_specification   \n",
      "\u001b[36;1m09f4cff0-90a7-5899-b9ed-1ef348aebdee\u001b[0m   spark-mllib_3.0-scala_2.12      2022-01-17T22:11:48.853Z   Machine Learning on Spark 3.0 with Scala 2.12        software_specification   \n",
      "\u001b[36;1m0b848dd4-e681-5599-be41-b5f6fccc6471\u001b[0m   pytorch-onnx_rt22.1-py3.9       2022-02-25T22:15:17.381Z   Software specification for Pytorch 1.10.1 on IBM …   software_specification   \n",
      "\u001b[36;1m0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda\u001b[0m   ai-function_0.1-py3.6           2022-01-17T22:11:48.811Z   Software specification for AI function on Python …   software_specification   \n",
      "\u001b[36;1m0e6e79df-875e-4f24-8ae9-62dcc2148306\u001b[0m   shiny-r3.6                      2022-01-17T22:11:48.847Z   R 3.6 with Shiny                                     software_specification   \n",
      "\u001b[36;1m10ac12d6-6b30-4ccd-8392-3e922c096a92\u001b[0m   pytorch_1.1-py3.6               2022-01-17T22:11:48.813Z   Software specification for Pytorch on Python 3.6     software_specification   \n",
      "\u001b[36;1m12b83a17-24d8-5082-900f-0ab31fbfd3cb\u001b[0m   runtime-22.1-py3.9              2022-02-25T22:15:17.383Z   Software specification for IBM Runtime 22.1 on Py…   software_specification   \n",
      "\u001b[36;1m154010fa-5b3b-4ac1-82af-4d5ee5abbc85\u001b[0m   scikit-learn_0.22-py3.6         2022-01-17T22:11:48.816Z   Software specification for Scikit-learn on Python…   software_specification   \n",
      "\u001b[36;1m1b199910-c7d5-5af4-b8f1-e86b760f9779\u001b[0m   pytorch-onnx_1.7-py3.8-edt      2022-01-17T22:11:48.845Z   Software specification for Pytorch 1.7 Elastic Di…   software_specification   \n",
      "\u001b[36;1m1b70aec3-ab34-4b87-8aa0-a4a3c8296a36\u001b[0m   default_r3.6                    2022-01-17T22:11:48.846Z   Default R 3.6                                        software_specification   \n",
      "\u001b[36;1m1d362186-7ad5-5b59-8b6c-9d0880bde37f\u001b[0m   pytorch-onnx_rt22.1-py3.9-edt   2022-02-25T22:15:17.379Z   Software specification for Pytorch 1.10.1 Elastic…   software_specification   \n",
      "\u001b[36;1m26215f05-08c3-5a41-a1b0-da66306ce658\u001b[0m   runtime-22.1-py3.9-cuda         2022-02-25T22:15:17.381Z   Software specification for IBM Runtime 22.1 on Py…   software_specification   \n",
      "\u001b[36;1m295addb5-9ef9-547e-9bf4-92ae3563e720\u001b[0m   do_py3.8                        2022-01-17T22:11:48.845Z   Python 3.8 with Decision Optimization                software_specification   \n",
      "\u001b[36;1m2aa0c932-798f-5ae9-abd6-15e0c2402fb5\u001b[0m   autoai-ts_3.8-py3.8             2022-01-17T22:11:48.825Z   Software specification for AutoAI TimeSeries on P…   software_specification   \n",
      "\u001b[36;1m2b73a275-7cbf-420b-a912-eae7f436e0bc\u001b[0m   tensorflow_1.15-py3.6           2022-01-17T22:11:48.817Z   Software specification for Tensorflow on Python 3…   software_specification   \n",
      "\u001b[36;1m2c8ef57d-2687-4b7d-acce-01f94976dac1\u001b[0m   pytorch_1.2-py3.6               2022-01-17T22:11:48.814Z   Software specification for Pytorch on Python 3.6     software_specification   \n",
      "\u001b[36;1m2e51f700-bca0-4b0d-88dc-5c6791338875\u001b[0m   spark-mllib_2.3                 2022-01-17T22:11:48.848Z   Machine Learning on Spark 2.3 with Python 3.6        software_specification   \n",
      "\u001b[36;1m32983cea-3f32-4400-8965-dde874a8d67e\u001b[0m   pytorch-onnx_1.1-py3.6-edt      2022-01-17T22:11:48.814Z   Software specification for Pytorch EDT with ONNX …   software_specification   \n",
      "\u001b[36;1m36507ebe-8770-55ba-ab2a-eafe787600e9\u001b[0m   spark-mllib_3.0-py37            2022-01-17T22:11:48.852Z   Machine Learning on Spark 3.0 with Python 3.7        software_specification   \n",
      "\u001b[36;1m390d21f8-e58b-4fac-9c55-d7ceda621326\u001b[0m   spark-mllib_2.4                 2022-01-17T22:11:48.850Z   Machine Learning on Spark 2.4 with Python 3.6        software_specification   \n",
      "\u001b[36;1m39e31acd-5f30-41dc-ae44-60233c80306e\u001b[0m   xgboost_0.82-py3.6              2022-01-17T22:11:48.817Z   Software specification for XGBoost on Python 3.6     software_specification   \n",
      "\u001b[36;1m40589d0e-7019-4e28-8daa-fb03b6f4fe12\u001b[0m   pytorch-onnx_1.2-py3.6-edt      2022-01-17T22:11:48.814Z   Software specification for Pytorch EDT with ONNX …   software_specification   \n",
      "\u001b[36;1m4269d26e-07ba-5d40-8f66-2d495b0c71f7\u001b[0m   autoai-ts_rt22.1-py3.9          2022-02-25T22:15:17.378Z   Software specification for AutoAI-TimeSeries on I…   software_specification   \n",
      "\u001b[36;1m42b92e18-d9ab-567f-988a-4240ba1ed5f7\u001b[0m   autoai-obm_3.0                  2022-02-25T22:15:17.384Z   Software specification for AutoAI OneButtonMachin…   software_specification   \n",
      "\u001b[36;1m435bfa8f-ddae-549a-826a-894368887231\u001b[0m   ai-function_0.2-py3.6           2022-01-17T22:11:48.810Z   Software specification for Python Functions on Py…   software_specification   \n",
      "\u001b[36;1m49403dff-92e9-4c87-a3d7-a42d0021c095\u001b[0m   spark-mllib_2.4-r_3.6           2022-01-17T22:11:48.850Z   Machine Learning on Spark 2.4 with R 3.6             software_specification   \n",
      "\u001b[36;1m4ff8d6c2-1343-4c18-85e1-689c965304d3\u001b[0m   xgboost_0.90-py3.6              2022-01-17T22:11:48.818Z   Software specification for XGBoost on Python 3.6     software_specification   \n",
      "\u001b[36;1m50f95b2a-bc16-43bb-bc94-b0bed208c60b\u001b[0m   pytorch-onnx_1.1-py3.6          2022-01-17T22:11:48.814Z   Software specification for Pytorch with ONNX on P…   software_specification   \n",
      "\u001b[36;1m52c57136-80fa-572e-8728-a5e7cbb42cde\u001b[0m   autoai-ts_3.9-py3.8             2022-01-17T22:11:48.825Z   Software specification for AutoAI-TimeSeries on P…   software_specification   \n",
      "\u001b[36;1m55a70f99-7320-4be5-9fb9-9edb5a443af5\u001b[0m   spark-mllib_2.4-scala_2.11      2022-01-17T22:11:48.850Z   Machine Learning on Spark 2.4 with Scala 2.11        software_specification   \n",
      "\u001b[36;1m5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9\u001b[0m   spark-mllib_3.0                 2022-01-17T22:11:48.848Z   Machine Learning on Spark 3.0                        software_specification   \n",
      "\u001b[36;1m5c2e37fa-80b8-5e77-840f-d912469614ee\u001b[0m   autoai-obm_2.0                  2022-01-17T22:11:48.849Z   Software specification for AutoAI OneButtonMachin…   software_specification   \n",
      "\u001b[36;1m5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b\u001b[0m   spss-modeler_18.1               2022-01-17T22:11:48.854Z   SPSS Modeler 18.1                                    software_specification   \n",
      "\u001b[36;1m5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e\u001b[0m   cuda-py3.8                      2022-01-17T22:11:48.825Z   Python 3.8 with CUDA                                 software_specification   \n",
      "\u001b[36;1m632d4b22-10aa-5180-88f0-f52dfb6444d7\u001b[0m   autoai-kb_3.1-py3.7             2022-01-17T22:11:48.818Z   Software specification for AutoAI KaggleBot on Py…   software_specification   \n",
      "\u001b[36;1m634d3cdc-b562-5bf9-a2d4-ea90a478456b\u001b[0m   pytorch-onnx_1.7-py3.8          2022-01-17T22:11:48.846Z   Software specification for Pytorch 1.3.1 on Pytho…   software_specification   \n",
      "\u001b[36;1m65e171d7-72d1-55d9-8ebb-f813d620c9bb\u001b[0m   tensorflow_2.4-py3.7            2022-01-17T22:11:48.824Z   Software specification for Tensorflow 2.4 on Pyth…   software_specification   \n",
      "\u001b[36;1m687eddc9-028a-4117-b9dd-e57b36f1efa5\u001b[0m   spss-modeler_18.2               2022-01-17T22:11:48.855Z   SPSS Modeler 18.2                                    software_specification   \n",
      "\u001b[36;1m692a6a4d-2c4d-45ff-a1ed-b167ee55469a\u001b[0m   pytorch-onnx_1.2-py3.6          2022-01-17T22:11:48.815Z   Software specification for Pytorch with ONNX on P…   software_specification   \n",
      "\u001b[36;1m75a3a4b0-6aa0-41b3-a618-48b1f56332a6\u001b[0m   do_12.9                         2022-01-17T22:11:48.809Z   Software specification for Decision Optimization     software_specification   \n",
      "\u001b[36;1m7abc992b-b685-532b-a122-a396a3cdbaab\u001b[0m   spark-mllib_2.4-py37            2022-01-17T22:11:48.849Z   Machine Learning on Spark 2.4 with Python 3.7        software_specification   \n",
      "\u001b[36;1m7bb3dbe2-da6e-4145-918d-b6d84aa93b6b\u001b[0m   caffe_1.0-py3.6                 2022-01-17T22:11:48.812Z   Caffe (community) on Python 3.6                      software_specification   \n",
      "\u001b[36;1m812c6631-42b7-5613-982b-02098e6c909c\u001b[0m   pytorch-onnx_1.7-py3.7          2022-01-17T22:11:48.823Z   Software specification for Pytorch 1.7.1 on Pytho…   software_specification   \n",
      "\u001b[36;1m82c79ece-4d12-40e6-8787-a7b9e0f62770\u001b[0m   cuda-py3.6                      2022-01-17T22:11:48.812Z   Python 3.6 with CUDA                                 software_specification   \n",
      "\u001b[36;1m8c1a58c6-62b5-4dc4-987a-df751c2756b6\u001b[0m   hybrid_0.1                      2022-01-17T22:11:48.810Z   Watson Machine Learning Hybrid framework             software_specification   \n",
      "\u001b[36;1m8d5d8a87-a912-54cf-81ec-3914adaa988d\u001b[0m   pytorch-onnx_1.3-py3.7          2022-01-17T22:11:48.823Z   Software specification for Pytorch 1.3.1 on Pytho…   software_specification   \n",
      "\u001b[36;1m8d863266-7927-4d1e-97d7-56a7f4c0a19b\u001b[0m   caffe-ibm_1.0-py3.6             2022-01-17T22:11:48.812Z   Caffe (IBM) on Python 3.6                            software_specification   \n",
      "\u001b[36;1m902d0051-84bd-4af6-ab6b-8f6aa6fdeabb\u001b[0m   spss-modeler_17.1               2022-01-17T22:11:48.853Z   SPSS Modeler 17.1                                    software_specification   \n",
      "\u001b[36;1m9100fd72-8159-4eb9-8a0b-a87e12eefa36\u001b[0m   do_12.10                        2022-01-17T22:11:48.808Z   Software specification for Decision Optimization     software_specification   \n",
      "\u001b[36;1m9447fa8b-2051-4d24-9eef-5acb0e3c59f8\u001b[0m   do_py3.7                        2022-01-17T22:11:48.822Z   (Deprecated) Python 3.7 with Decision Optimization   software_specification   \n",
      "\u001b[36;1m94bb6052-c837-589d-83f1-f4142f219e32\u001b[0m   spark-mllib_3.0-r_3.6           2022-01-17T22:11:48.853Z   Machine Learning on Spark 3.0 with R 3.6             software_specification   \n",
      "\u001b[36;1m94e9652b-7f2d-59d5-ba5a-23a414ea488f\u001b[0m   cuda-py3.7-opence               2022-01-17T22:11:48.820Z   Python 3.7 with CUDA                                 software_specification   \n",
      "\u001b[36;1m9a44990c-1aa1-4c7d-baf8-c4099011741c\u001b[0m   cuda-py3.7                      2022-01-17T22:11:48.820Z   (Deprecated) Python 3.7 with CUDA                    software_specification   \n",
      "\u001b[36;1m9b3f9040-9cee-4ead-8d7a-780600f542f7\u001b[0m   hybrid_0.2                      2022-01-17T22:11:48.810Z   Watson Machine Learning Hybrid framework             software_specification   \n",
      "\u001b[36;1m9f7a8fc1-4d3c-5e65-ab90-41fa8de2d418\u001b[0m   spark-mllib_3.0-py38            2022-01-17T22:11:48.852Z   Machine Learning on Spark 3.0 with Python 3.8        software_specification   \n",
      "\u001b[36;1ma3515e34-e372-5244-8609-f14713deac9d\u001b[0m   autoai-kb_3.2-py3.7             2022-01-17T22:11:48.818Z   Software specification for AutoAI KaggleBot on Py…   software_specification   \n",
      "\u001b[36;1ma545cca3-02df-5c61-9e88-998b09dc79af\u001b[0m   autoai-kb_3.3-py3.7             2022-01-17T22:11:48.819Z   Software specification for AutoAI KaggleBot on Py…   software_specification   \n",
      "\u001b[36;1ma7e7dbf1-1d03-5544-994d-e5ec845ce99a\u001b[0m   runtime-22.1-py3.9-do           2022-02-25T22:15:17.382Z   Software specification for IBM Runtime 22.1 on Py…   software_specification   \n",
      "\u001b[36;1mab9e1b80-f2ce-592c-a7d2-4f2344f77194\u001b[0m   default_py3.8                   2022-01-17T22:11:48.844Z   Default Python 3.8                                   software_specification   \n",
      "\u001b[36;1macd9c798-6974-5d2f-a657-ce06e986df4d\u001b[0m   tensorflow_rt22.1-py3.9         2022-02-25T22:15:17.384Z   Software specification for Tensorflow 2.7 on IBM …   software_specification   \n",
      "\u001b[36;1maf10f35f-69fa-5d66-9bf5-acb58434263a\u001b[0m   autoai-obm_2.0 with Spark 3.0   2022-01-17T22:11:48.851Z   Software specification for AutoAI OneButtonMachin…   software_specification   \n",
      "\u001b[36;1mc2057dd4-f42c-5f77-a02f-72bdbd3282c9\u001b[0m   default_py3.7_opence            2022-01-17T22:11:48.820Z   Default Python 3.7                                   software_specification   \n",
      "\u001b[36;1mc4032338-2a40-500a-beef-b01ab2667e27\u001b[0m   tensorflow_2.1-py3.7            2022-01-17T22:11:48.824Z   Software specification for Tensorflow 2.1 on Pyth…   software_specification   \n",
      "\u001b[36;1mcc8f8976-b74a-551a-bb66-6377f8d865b4\u001b[0m   do_py3.7_opence                 2022-01-17T22:11:48.821Z   Python 3.7 with Decision Optimization                software_specification   \n",
      "\u001b[36;1md139f196-e04b-5d8b-9140-9a10ca1fa91a\u001b[0m   autoai-kb_3.0-py3.6             2022-01-17T22:11:48.811Z   Software specification for AutoAI KaggleBot on Py…   software_specification   \n",
      "\u001b[36;1md82546d5-dd78-5fbb-9131-2ec309bc56ed\u001b[0m   spark-mllib_3.0-py36            2022-01-17T22:11:48.852Z   Machine Learning on Spark 3.0 with Python 3.6        software_specification   \n",
      "\u001b[36;1mda9b39c3-758c-5a4f-9cfd-457dd4d8c395\u001b[0m   autoai-kb_3.4-py3.8             2022-01-17T22:11:48.824Z   Software specification for AutoAI KaggleBot on Py…   software_specification   \n",
      "\u001b[36;1mdb6afe93-665f-5910-b117-d879897404d9\u001b[0m   autoai-kb_rt22.1-py3.9          2022-02-25T22:15:17.377Z   Software specification for AutoAI KaggleBot (Pyth…   software_specification   \n",
      "\u001b[36;1mdeef04f0-0c42-5147-9711-89f9904299db\u001b[0m   autoai-ts_1.0-py3.7             2022-01-17T22:11:48.819Z   Software specification for AutoAI-TimeSeries on P…   software_specification   \n",
      "\u001b[36;1me384fce5-fdd1-53f8-bc71-11326c9c635f\u001b[0m   tensorflow_2.1-py3.7-horovod    2022-01-17T22:11:48.824Z   Software specification for Tensorflow 2.1 on Pyth…   software_specification   \n",
      "\u001b[36;1me441dfdb-bcd1-5310-9da4-906127712abf\u001b[0m   spark-mllib_3.0-py39            2022-02-25T22:15:17.383Z   Machine Learning on Spark 3.0 with Python 3.9        software_specification   \n",
      "\u001b[36;1me4429883-c883-42b6-87a8-f419d64088cd\u001b[0m   default_py3.7                   2022-01-17T22:11:48.821Z   (Deprecated) Default Python 3.7                      software_specification   \n",
      "\u001b[36;1mef1726a6-c84f-5a2c-aac6-5b80e39b8af0\u001b[0m   pytorch-onnx_1.7-py3.7-edt      2022-01-17T22:11:48.823Z   Software specification for Pytorch 1.7 Elastic Di…   software_specification   \n",
      "\u001b[36;1mf686cdd9-7904-5f9d-a732-01b0d6b10dc5\u001b[0m   do_20.1                         2022-01-17T22:11:48.809Z   Software specification for Decision Optimization     software_specification   \n",
      "\u001b[36;1mfe185c44-9a99-5425-986b-59bd1d2eda46\u001b[0m   tensorflow_2.4-py3.8            2022-01-17T22:11:48.846Z   Software specification for Tensorflow 2.4 on Pyth…   software_specification   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment software-specification list --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "5bce9e84-75ba-44a0-b85d-def67102a8ed",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base software specification id: ab9e1b80-f2ce-592c-a7d2-4f2344f77194\n"
     ]
    }
   ],
   "source": [
    "base_sw_spec_name = \"Default Python 3.8\"\n",
    "query_string = \"(resources[?metadata.description == '{}'].metadata.asset_id)[0]\".format(base_sw_spec_name)\n",
    "\n",
    "result = ! cpdctl environment software-specification list --project-id {project_id} --output json -j \"{query_string}\" --raw-output\n",
    "base_sw_spec_id = result.s\n",
    "print(\"base software specification id: {}\".format(base_sw_spec_id))\n",
    "\n",
    "# You can also specify your base software specification id directly:\n",
    "# based_sw_spec_id = \"Your base software specification ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02040fb8-be3f-475f-b9e3-1d72a4bd72cd"
   },
   "source": [
    "Create a custom software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "b05972e8-9032-4396-ad4a-a0655d63f433",
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_sw_spec_name = \"my_sw_spec\"\n",
    "\n",
    "base_sw_spec = {\n",
    "    'guid': base_sw_spec_id\n",
    "}\n",
    "\n",
    "base_sw_spec_json = json.dumps(base_sw_spec)\n",
    "\n",
    "sw_conf = {}\n",
    "sw_conf_json = json.dumps(sw_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "030e2604-7ac7-405a-ae98-4bf05673a4e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom software specification id: 6351dab8-e988-49e2-b9a6-84abae4de332\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment software-specification create --project-id {project_id} --name {custom_sw_spec_name} --base-software-specification '{base_sw_spec_json}' --software-configuration '{sw_conf_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "custom_sw_spec_id = result.s\n",
    "print(\"custom software specification id: {}\".format(custom_sw_spec_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7759a23-4435-49c3-acb0-fffa00b87076"
   },
   "source": [
    "### 5.2 Adding additional packages <a class=\"anchor\" id=\"part5.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9edd8ff9-6147-4523-824e-27d363a099ac"
   },
   "source": [
    "Create a package extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "6ff35d5e-780e-4d9c-a015-713aeacf862a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkg_name = \"my_test_packages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "e34bfa4d-ac25-4485-938b-372ff483729f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package extension id: 232ed7dc-17ce-4897-bead-2396fdf86123\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment package-extension create --name {pkg_name} --type \"conda_yml\" --project-id {project_id}  --output json\n",
    "pkg_ext_id = json.loads(result.s)['metadata']['asset_id']\n",
    "print(\"package extension id: {}\".format(pkg_ext_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ddfa245-5214-48c3-8396-0507160d7222"
   },
   "source": [
    "Get the path to where you want to upload the additional packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "44f967f5-8bfc-4b32-83d1-ca8451fdb443",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path where asset should be uploaded: package_extension/my_test_packages_b4Bzd2Tvk.yml\n"
     ]
    }
   ],
   "source": [
    "pkg_ext_href = json.loads(result.s)['entity']['package_extension']['href'].split('/')[4].split('?')[0]\n",
    "remote_pkg_path = \"package_extension/{}\".format(pkg_ext_href)\n",
    "print(\"path where asset should be uploaded: {}\".format(remote_pkg_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ff77db2-539c-4fab-b1b6-5c4812568550"
   },
   "source": [
    "Define a conda-yaml file listing additional packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "bdc3a451-a358-4540-bfd0-7d9fdec9e4f5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_yaml = \"\"\"\n",
    "channels:\n",
    "  - defaults\n",
    "\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - fuzzywuzzy\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('my-pkg-ext.yaml', 'w') as f:\n",
    "    f.write(my_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1bc63d3-11d0-4cd7-8d96-5706f62fb838"
   },
   "source": [
    "Upload additional packages to the path returned in the previous command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "e4c7124f-2e00-4b56-a79b-c607e58c2ea2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_pkg_path = \"./my-pkg-ext.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "44bc9c2f-94fc-4403-9daf-5090bd8e7669",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl asset file upload --path \"{remote_pkg_path}\" --file {local_pkg_path} --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "91afd87e-965e-429f-a59f-79031c3f127f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment package-extension upload-complete --package-extension-id {pkg_ext_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f3b94f0-ae53-41b4-b4fb-033a5e2b63f9"
   },
   "source": [
    "Add the package extension into the custom software specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "52359c8b-d14e-4741-aea7-59b122b383a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[32;1mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment software-specification add-package-extensions --software-specification-id {custom_sw_spec_id} --package-extension-id {pkg_ext_id} --project-id {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e178ba16-c3aa-4c3a-9463-25c649440dad"
   },
   "source": [
    "### 5.3 Creating a custom environment <a class=\"anchor\" id=\"part5.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90d1bf4d-769e-42fb-a38f-7b30ee505d3b"
   },
   "source": [
    "List all the hardware specifications in your project and choose one that fits your custom environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "ac54a5d4-3530-4cf7-9214-5f217555e819",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mID\u001b[0m                                     \u001b[1mName\u001b[0m            \u001b[1mCreated\u001b[0m                    \u001b[1mDescription\u001b[0m                                          \u001b[1mType\u001b[0m   \n",
      "\u001b[36;1m5a1f0e64-e420-55ce-bd7a-f6d00bb942cf\u001b[0m   ML              2022-01-17T22:11:49.321Z   A hardware specification providing 4 CPU cores an…   hardware_specification   \n",
      "\u001b[36;1ma02f3ab5-6964-4f06-a870-c7cc69187895\u001b[0m   V100x2          2022-01-17T22:11:49.322Z   A hardware specification providing 52 CPU cores a…   hardware_specification   \n",
      "\u001b[36;1ma6c4923b-b8e4-444c-9f43-8a7ec3020110\u001b[0m   L               2022-01-17T22:11:49.320Z   A hardware specification providing 8 CPU cores an…   hardware_specification   \n",
      "\u001b[36;1mac59d20a-9c7c-4504-a853-788ef35969da\u001b[0m   Default Spark   2022-01-17T22:11:49.319Z   A hardware specification for Spark with 1 CPU and…   hardware_specification   \n",
      "\u001b[36;1mb128f957-581d-46d0-95b6-8af5cd5be580\u001b[0m   XXS             2022-01-17T22:11:49.324Z   A hardware specification providing one CPU core a…   hardware_specification   \n",
      "\u001b[36;1mb2232f7a-bfad-4822-9bce-6ba1af49217a\u001b[0m   M-Spark         2022-01-17T22:11:49.320Z   A hardware specification for Spark service with 2…   hardware_specification   \n",
      "\u001b[36;1mb305a34b-acb5-4850-a44a-f1f15e304a20\u001b[0m   V100x4          2022-01-17T22:11:49.323Z   A hardware specification providing 104 CPU cores …   hardware_specification   \n",
      "\u001b[36;1mc076e82c-b2a7-4d20-9c0f-1f0c2fdf5a24\u001b[0m   M               2022-01-17T22:11:49.320Z   A hardware specification providing 4 CPU cores an…   hardware_specification   \n",
      "\u001b[36;1mc1791762-1333-4dd3-b7bb-228ae287da31\u001b[0m   XL-Spark        2022-01-17T22:11:49.323Z   A hardware specification for Spark service with 3…   hardware_specification   \n",
      "\u001b[36;1mcf70f086-916d-4684-91a7-264c49c6d425\u001b[0m   K80             2022-01-17T22:11:49.319Z   A hardware specification providing 4 CPU cores an…   hardware_specification   \n",
      "\u001b[36;1md0aa1ae8-a889-42e2-a099-041b604b9289\u001b[0m   XL              2022-01-17T22:11:49.323Z   A hardware specification providing 16 CPU cores a…   hardware_specification   \n",
      "\u001b[36;1md0f52aa1-4312-40f6-ad84-f16cf5c6da9e\u001b[0m   K80x2           2022-01-17T22:11:49.319Z   A hardware specification providing 8 CPU cores an…   hardware_specification   \n",
      "\u001b[36;1md92943ba-9f47-407d-9280-c85281687a1e\u001b[0m   S-Spark         2022-01-17T22:11:49.321Z   A hardware specification for Spark service with 1…   hardware_specification   \n",
      "\u001b[36;1me18b1866-e8fa-49c8-9aa5-dfaaed6ffa43\u001b[0m   XS-Spark        2022-01-17T22:11:49.323Z   A hardware specification for Spark with 1 CPU and…   hardware_specification   \n",
      "\u001b[36;1me7ed1d6c-2e89-42d7-aed5-863b972c1d2b\u001b[0m   S               2022-01-17T22:11:49.321Z   A hardware specification providing 2 CPU cores an…   hardware_specification   \n",
      "\u001b[36;1mec104857-0389-4649-af8e-971fc11982d0\u001b[0m   K80x4           2022-01-17T22:11:49.319Z   A hardware specification providing 16 CPU cores a…   hardware_specification   \n",
      "\u001b[36;1mf132f14a-6c0f-4570-b87c-98ad1e297953\u001b[0m   L-Spark         2022-01-17T22:11:49.320Z   A hardware specification for Spark service with 2…   hardware_specification   \n",
      "\u001b[36;1mf327bdf7-5634-43d8-b1e3-445afeaf18b9\u001b[0m   V100            2022-01-17T22:11:49.322Z   A hardware specification providing 26 CPU cores a…   hardware_specification   \n",
      "\u001b[36;1mf3ebac7d-0a75-410c-8b48-a931428cc4c5\u001b[0m   XS              2022-01-17T22:11:49.323Z   A hardware specification providing one CPU core a…   hardware_specification   \n"
     ]
    }
   ],
   "source": [
    "! cpdctl environment hardware-specification list --project-id {project_id} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "f2e5a6e0-5dfc-4217-83e3-d4f42b97f982",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hardware specification id: f3ebac7d-0a75-410c-8b48-a931428cc4c5\n"
     ]
    }
   ],
   "source": [
    "hw_spec_keyword_1 = \"one CPU core\"\n",
    "hw_spec_keyword_2 = \"4 GiB of memory\"\n",
    "query_string = \"(resources[?contains(metadata.description, '{}') && contains(metadata.description, '{}')].metadata.asset_id)[0]\".format(hw_spec_keyword_1, hw_spec_keyword_2)\n",
    "\n",
    "result = ! cpdctl environment hardware-specification list --project-id {project_id}  --output json -j \"{query_string}\" --raw-output\n",
    "hw_spec_id = result.s\n",
    "print(\"hardware specification id: {}\".format(hw_spec_id))\n",
    "\n",
    "# You can also specify your hardware specification id directly:\n",
    "# hw_spec_id = \"Your base software specification ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0792a4a7-c7b4-4ff9-b734-84cb9e72527b"
   },
   "source": [
    "Create a custom environment by specifying the hardware specification, the custom software specification and the tool specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "bddd2ecd-d116-47ad-b50a-876147796d57",
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_name = \"my_custom_env\"\n",
    "hw_spec = {\n",
    "    'guid': hw_spec_id\n",
    "}\n",
    "custom_sw_spec = {\n",
    "    'guid': custom_sw_spec_id\n",
    "}\n",
    "custom_sw_spec_json = json.dumps(custom_sw_spec)\n",
    "tool_spec = {\n",
    "    'supported_kernels': [{\n",
    "        'language': 'python', \n",
    "        'version': '3.7', \n",
    "        'display_name': 'Python 3.7'\n",
    "    }]\n",
    "}\n",
    "hw_spec_json = json.dumps(hw_spec)\n",
    "tool_spec_json = json.dumps(tool_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "a4169d6f-9c30-4906-8497-2506a1f09bc2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom environment id: 43306410-dae7-40de-87a7-3abf806473c8\n"
     ]
    }
   ],
   "source": [
    "result = ! cpdctl environment create --project-id {project_id} --type \"notebook\" --name {env_name} --display-name {env_name} --hardware-specification '{hw_spec_json}' --software-specification '{custom_sw_spec_json}' --tools-specification '{tool_spec_json}' --output json -j \"metadata.asset_id\" --raw-output\n",
    "custom_env_id = result.s\n",
    "print(\"custom environment id: {}\".format(custom_env_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f45141e6-ab31-475f-95ad-009d71745585"
   },
   "source": [
    "Now you can use this custom environment when you create a new notebook asset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2065ea6-a0f0-499e-b81a-dad3b214e996"
   },
   "source": [
    "Copyright © 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
